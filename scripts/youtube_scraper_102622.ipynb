{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8b9472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jetcalz07/opt/miniconda3/envs/nlp/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import spacy\n",
    "from googleapiclient.discovery import build\n",
    "from youtube_helpers_v2 import get_channel_playlists, get_video_ids, get_video_details\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "path = '/Users/jetcalz07/Desktop/MIDS/W266_NLP/nlp_podcast_segmentation/'\n",
    "load_scripts = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60517180",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyDTr6GYriQpML3rwVB_M4aVhixseOxVO4U'\n",
    "channel_ids = ['UCSHZKyawb77ixDdsGog4iWA', # Lex Fridman\n",
    "               'UCESLZhusAkFfsNsApnjF_Cg', # All-In\n",
    "               'UCNNTZgxNQuBrhbO0VrG8woA', # No Jumper\n",
    "               'UC0-swBG9Ne0Vh4OuoJ2bjbA', # rSlash\n",
    "               'UC2D2CMWXMOVWx7giW1n3LIg', # Andrew Huberman\n",
    "               'UCxcTeAKWJca6XyJ37_ZoKIQ' , # Pat McAfee\n",
    "               'UC5PstSsGrRwj2o6asQpC4Rg' , # Flagrant\n",
    "               'UC5sqmi33b7l9kIYa0yASOmQ' , # Fresh and Fit\n",
    "               'UCbk_QsfaFZG6PdQeCvaYXJQ' , # Jay Shetty\n",
    "               'UCGeBogGDZ9W3dsGx-mWQGJA', # Logan Paul\n",
    "               'UCL_f53ZEJxp8TtlOkHwMV9Q', # JP\n",
    "               'UCAVojJ1k03GZzjSbdXXunkw', # Shane2\n",
    "              ]\n",
    "\n",
    "channel_ids = ['UCSHZKyawb77ixDdsGog4iWA', # Lex Fridman\n",
    "              ]\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfc8d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin channel 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:04<00:04,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 - 0.0\n",
      "0.0 - 11.0\n",
      "666.12 - 665.0\n",
      "772.1 - 771.0\n",
      "1381.2 - 1377.0\n",
      "1529.94 - 1533.0\n",
      "4477.44 - 4483.0\n",
      "5416.86 - 5415.0\n",
      "5695.199 - 5695.0\n",
      "5821.679 - 5824.0\n",
      "6543.0 - 6547.0\n",
      "6722.94 - 6741.0\n",
      "7319.34 - 7340.0\n",
      "7383.239 - 7392.0\n",
      "8208.24 - 8173.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:20<00:00, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06 - 0.0\n",
      "145.379 - 141.0\n",
      "1699.08 - 1713.0\n",
      "2710.26 - 2690.0\n",
      "3310.38 - 3294.0\n",
      "4718.76 - 4720.0\n",
      "5599.32 - 5601.0\n",
      "8473.38 - 8468.0\n",
      "10717.26 - 10718.0\n",
      "12296.88 - 12306.0\n",
      "17794.32 - 17774.0\n",
      "18916.44 - 18912.0\n",
      "20671.98 - 20671.0\n",
      "21098.94 - 21099.0\n",
      "21935.04 - 21939.0\n",
      "22907.34 - 22914.0\n",
      "24054.36 - 24042.0\n",
      "25094.458 - 25095.0\n",
      "25811.218 - 25814.0\n",
      "27786.84 - 27788.0\n",
      "Total Channels: 1, Total Videos: 713\n",
      "Total videos with timestamps & scripts: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Video_Id</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Transcript-Source</th>\n",
       "      <th>Sentence_Word_Lists</th>\n",
       "      <th>Transition_Labels</th>\n",
       "      <th>Sentence_Times</th>\n",
       "      <th>Segment_Times_Secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lex Fridman</td>\n",
       "      <td>Kanye 'Ye' West | Lex Fridman Podcast #332</td>\n",
       "      <td>Ye is a legendary artist, producer, and design...</td>\n",
       "      <td>4AWLcxTGZPA</td>\n",
       "      <td>[{'text': 'the following is a conversation wit...</td>\n",
       "      <td>auto</td>\n",
       "      <td>[[the, following, is, a, conversation, with, y...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 33.42, 36.12, 37.26, 41.399, 131.4, 141....</td>\n",
       "      <td>[0.0, 11.0, 665.0, 771.0, 1377.0, 1533.0, 4483...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lex Fridman</td>\n",
       "      <td>Balaji Srinivasan: How to Fix Government, Twit...</td>\n",
       "      <td>Balaji Srinivasan is an angel investor, tech f...</td>\n",
       "      <td>VeH7qKZr0WI</td>\n",
       "      <td>[{'text': 'Donald Trump was probably the bigge...</td>\n",
       "      <td>auto</td>\n",
       "      <td>[[Donald, Trump, was, probably, the, biggest, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.06, 23.34, 44.219, 58.379, 145.379, 145.379...</td>\n",
       "      <td>[0.0, 141.0, 1713.0, 2690.0, 3294.0, 4720.0, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Channel                                              Title  \\\n",
       "0  Lex Fridman         Kanye 'Ye' West | Lex Fridman Podcast #332   \n",
       "1  Lex Fridman  Balaji Srinivasan: How to Fix Government, Twit...   \n",
       "\n",
       "                                         Description     Video_Id  \\\n",
       "0  Ye is a legendary artist, producer, and design...  4AWLcxTGZPA   \n",
       "1  Balaji Srinivasan is an angel investor, tech f...  VeH7qKZr0WI   \n",
       "\n",
       "                                          Transcript Transcript-Source  \\\n",
       "0  [{'text': 'the following is a conversation wit...              auto   \n",
       "1  [{'text': 'Donald Trump was probably the bigge...              auto   \n",
       "\n",
       "                                 Sentence_Word_Lists  \\\n",
       "0  [[the, following, is, a, conversation, with, y...   \n",
       "1  [[Donald, Trump, was, probably, the, biggest, ...   \n",
       "\n",
       "                                   Transition_Labels  \\\n",
       "0  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      Sentence_Times  \\\n",
       "0  [0.0, 33.42, 36.12, 37.26, 41.399, 131.4, 141....   \n",
       "1  [0.06, 23.34, 44.219, 58.379, 145.379, 145.379...   \n",
       "\n",
       "                                  Segment_Times_Secs  \n",
       "0  [0.0, 11.0, 665.0, 771.0, 1377.0, 1533.0, 4483...  \n",
       "1  [0.0, 141.0, 1713.0, 2690.0, 3294.0, 4720.0, 5...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Execute functions to collect data from Youtube channels\n",
    "\n",
    "if not load_scripts:\n",
    "    # Get playlist ids for channel\n",
    "    channel_df = pd.DataFrame(get_channel_playlists(youtube, channel_ids))\n",
    "\n",
    "    # Loop through channels, get video ids\n",
    "    v_ids = np.array([])\n",
    "    for idx, row in channel_df.iterrows():\n",
    "        print(f\"Begin channel {idx+1}\")\n",
    "        playlist_id = row['playlist_id']\n",
    "        channel_vids = get_video_ids(youtube, playlist_id)\n",
    "        v_ids = np.append(v_ids, channel_vids)\n",
    "\n",
    "    # Loop through videos, get timestamp, script information\n",
    "    vid_details = pd.DataFrame(get_video_details(youtube, v_ids, splitter='spacy', nlp = nlp))\n",
    "    print(f\"Total Channels: {len(channel_df)}, Total Videos: {len(v_ids)}\")\n",
    "    print(f\"Total videos with timestamps & scripts: {len(vid_details)}\")\n",
    "    vid_details.to_csv(path+f'data/yt_scripts_segments_v102622_{len(vid_details)}.csv', index=False)\n",
    "\n",
    "else:\n",
    "    vid_details = pd.read_csv(path+'data/yt_scripts_segments_v102622.csv')\n",
    "    vid_details['Transcript'] = vid_details['Transcript'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "vid_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c1daa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "['Donald', 'Trump', 'was', 'probably', 'the', 'biggest', 'person', 'ever', 'to', 'be']\n",
      "141.0\n",
      "['Im', 'curious']\n",
      "1713.0\n",
      "['and', 'then', 'we', 'make', 'that', 'very', 'hard', 'to', 'change', 'because']\n",
      "2690.0\n",
      "['okay']\n",
      "3294.0\n",
      "['and', 'I', 'was', 'like', 'very', 'large', 'like', '20', '000', 'people']\n",
      "4720.0\n",
      "['but', 'this', 'is', 'um', 'exit', 'is', 'the', 'anti-genocide', 'technology', 'right']\n",
      "5601.0\n",
      "['but', 'okay']\n",
      "8468.0\n",
      "['and', 'uh', 'I', 'think', 'the', 'world', 'is', 'a', 'better', 'place']\n",
      "10718.0\n",
      "['yeah', 'Wikipedia', 'media', 'and', 'Academia', 'are', 'all', 'related', 'to', 'the']\n",
      "12306.0\n",
      "['but', 'yes', 'for', 'important', 'people', 'like', 'a', 'president', 'United', 'States']\n",
      "17774.0\n",
      "['okay']\n",
      "18912.0\n",
      "['do', 'you', 'understand', 'why', 'that', 'was', 'done', 'can', 'you', 'still']\n",
      "20671.0\n",
      "['you', 'know', 'we', 'want', 'to', 'avoid', 'a', 'hot', 'war', 'between']\n",
      "21099.0\n",
      "['if', 'if', 'I', 'or', 'anyone', 'were', 'to', 'have', 'a', 'conversation']\n",
      "21939.0\n",
      "['V3']\n",
      "22914.0\n",
      "['kind', 'of', 'okay']\n",
      "24042.0\n",
      "['yes', 'do', 'you', 'think', 'youll', 'go', 'uh', 'to', 'take', 'on']\n",
      "25095.0\n",
      "['AI', 'and', 'AR']\n",
      "25814.0\n",
      "['so', 'um', 'youre', 'an', 'incredibly', 'successful', 'person', 'yourself', 'you', 'taught']\n",
      "27788.0\n",
      "['okay']\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "labels = vid_details.loc[i, 'Transition_Labels']\n",
    "sentences = vid_details.loc[i, 'Sentence_Word_Lists']\n",
    "times = vid_details.loc[i, 'Segment_Times_Secs']\n",
    "inds = np.where(labels == 1)[0]\n",
    "\n",
    "for i in range(len(inds)):\n",
    "    ind = inds[i]\n",
    "    print(times[i])\n",
    "    print(sentences[ind][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1bda1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'I', 'saw', 'something', 'that', 'I', 'thought', 'was', 'really', 'good', 'recently', 'thats', 'a', 'good', 'um', 'first', 'cut', 'thats', 'something', 'that', 'I', 'might', 'want', 'to', 'include', 'I', 'credit', 'him', 'of', 'course', 'in', 'V', 'to', 'the', 'book', 'a', 'digital', 'Bill', 'of', 'Rights']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[inds[-1]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2470ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "766380c61e6eecc7f361b76fca150175cbf549793dc3a73d27fd98d75ec4b455"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
