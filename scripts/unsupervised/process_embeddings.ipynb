{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccrpWUv5Ard"
      },
      "source": [
        "# Process embeddings.\n",
        "\n",
        "### Description\n",
        "This pipeline process sentence embeddings, calculates predictions and performance metrics. The process consists of loading the tensor files from the \"create_embeddings\" pipeline output folder and calculate the predicted value for the topic segmentation task. With the predicted values we calculate the PK and WD metrics for each of the podcasts and for the overall dataset. Due to the size of the dataset (~4000 videos) we save each metric result  to a specific folder to easily replicate the measurments. The Results are saved in the \"./data/metric_results/dataset_name/pre-trained model/\" folder. Outputs of this pipeline are:\n",
        "\n",
        "- Y_hat_list: List of arrays containing each prediction array per podcast\n",
        "- T_hat_list: List of arrays containing each topic change index per podcast\n",
        "- sims_list: List of arrays contianing the similarity vectors calculated per podcast\n",
        "- results_pre-trained model name.csv: CSV with all PK and WD values per podcast.\n",
        "\n",
        "Parameters:\n",
        "- dataset_name: Name of the dataset to be loaded and processed.\n",
        "- model_name: Type of model to create the sentence embeddings.\n",
        "- pre_trained_model: Pre trained model to use in the sentence embeddings process\n",
        "- dim_redux_method: What type of dimensionality reduction process to use to create the sentence embeddings from the token embeddings.\n",
        "- print_debug: Print a message everytime an embedding is created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUGaCOWLAhjR",
        "outputId": "fde59d7a-7096-48f5-841d-23e5d62a1c3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 51.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 47.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 45.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 451 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 75.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 77.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 8.8 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Imported Packages and Libraries\n",
        "!pip install nlp --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip install -U sentence-transformers --quiet\n",
        "\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "from nlp import load_dataset\n",
        "import random\n",
        "\n",
        "import seaborn as sns\n",
        "from pprint import pprint \n",
        "\n",
        "# Utilites\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "from numpy.linalg import norm\n",
        "from numpy import dot\n",
        "import os # accessing directory structure\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import csv\n",
        "import time\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from torch._C import NoneType\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# JSON\n",
        "import json\n",
        "\n",
        "# Embeddings\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import sklearn as sk\n",
        "import nltk\n",
        "from nltk.data import find\n",
        "from nltk.metrics.segmentation import windowdiff\n",
        "from nltk.metrics.segmentation import pk\n",
        "\n",
        "# Pandas CSV processing\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Formatting options for float number in numpy\n",
        "float_formatter = \"{:.4f}\".format\n",
        "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "path = \"/content/drive/MyDrive/W266/project/nlp_podcast_segmentation/\" #@param [\"/content/drive/MyDrive/W266/project/nlp_podcast_segmentation/\", \"other\"] {allow-input: true}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaveyl6nBHqt",
        "outputId": "72799671-56ae-4fc3-d9ec-3a01efea8c7d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filename:                  yt_scripts_segments_split_n5_111422.csv\n",
            "Dataset:                   YouTube\n",
            "Model:                     SBERT\n",
            "Pre-trained Model:         all-MiniLM-L6-v2\n",
            "Dimensionality Redyction:  meanpooling\n"
          ]
        }
      ],
      "source": [
        "#@title Choose parameters\n",
        "# Choose parameters\n",
        "\n",
        "dataset_name =        \"YouTube/yt_scripts_segments_split_n5_111422.csv\" #@param [\"AMIDataset\", \"YouTube/yt_scripts_segments_yt_simple_110922.csv\", \"YouTube/yt_scripts_segments_split_n5_111422.csv\", \"YouTube/yt_scripts_segments_split_n3_111422.csv\",\"YouTube/yt_small_spacy_dev.csv\", \"YouTube/yt_scripts_segments_spacy_111022.csv\", \"YouTube/yt_scripts_segments_split_n5_111422_subset10.csv\",\"YouTube/yt_scripts_segments_split_n10_112922.csv\"]\n",
        "model_name =          \"SBERT\" #@param [\"SBERT\", \"Universal Sentence Encoder\"]\n",
        "pre_trained_model =   \"all-MiniLM-L6-v2\" #@param [\"all-mpnet-base-v2\",\"stsb-mpnet-base-v2\", \"all-MiniLM-L6-v2\", \"multi-qa-mpnet-base-dot-v1\", \"nli-bert-large-max-pooling\", \"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\", \"/content/drive/MyDrive/W266/project/nlp_podcast_segmentation/scripts/ricardo/use/\"]\n",
        "dim_redux_method =    'meanpooling' #@param [\"meanpooling\", \"maxpooling\"]\n",
        "print_debug =         \"Yes\" #@param [\"Yes\", \"No\"]\n",
        "similarity_window =   \"1\" #@param [\"Average of sentences\"] {allow-input: true}\n",
        "z_partition_dataset = \"all\" #@param [\"train\", \"test\", \"all\"] \n",
        "Z =                   \"1\" #@param [\"1.4\"] {allow-input: true}\n",
        "metric_calculation =  \"average\" #@param [\"smooth\", \"average\",\"append\"] \n",
        "baseline =  \"NO\" #@param [\"even\", \"random\",\"none\",\"NO\"] \n",
        "Z = float(Z)\n",
        "\n",
        "if model_name == \"Universal Sentence Encoder\":\n",
        "  pre_trained_model_url = pre_trained_model\n",
        "  pre_trained_model = str(pre_trained_model.split(\"/\")[-2]) + \"-\" + str(pre_trained_model.split(\"/\")[-1]) \n",
        "\n",
        "filename = \"\"\n",
        "if len(dataset_name.split(\"/\")) > 1:\n",
        "  if dataset_name.split(\"/\")[-2] == \"YouTube\":\n",
        "    filename = dataset_name.split(\"/\")[-1]\n",
        "    dataset_name = dataset_name.split(\"/\")[-2]\n",
        "    print(\"Filename:                  \" + filename)\n",
        "print(\"Dataset:                   \" + dataset_name)\n",
        "print(\"Model:                     \" + model_name)\n",
        "print(\"Pre-trained Model:         \" + pre_trained_model)\n",
        "print(\"Dimensionality Redyction:  \" + dim_redux_method)\n",
        "\n",
        "# Define loading functions\n",
        "\n",
        "#Remove adjacent topic changes\n",
        "def clean_adj_topic(topic_list):\n",
        "  '''\n",
        "  Removes the second topic change from two neighboring topic changes\n",
        "  Example: [0,1,1,0,1,1,1,0,1] would be cleaned to [0,1,0,0,1,0,1,0,1]\n",
        "  '''\n",
        "\n",
        "  idx = 1\n",
        "  N = len(topic_list)\n",
        "  clean_list = topic_list.copy()\n",
        "\n",
        "  while(idx < N):\n",
        "    if(clean_list[idx] == 1 and clean_list[idx-1] == 1):\n",
        "      clean_list[idx] = 0\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "  return clean_list\n",
        "\n",
        "# average_sentences\n",
        "# Calculate average sentences\n",
        "def average_sentences(topic_list):\n",
        "  '''\n",
        "  Counts the number of sentences between topics\n",
        "  input: topic labels\n",
        "  returns: average number of sentences between topics\n",
        "  '''\n",
        "\n",
        "  idx = 0\n",
        "  N = len(topic_list)\n",
        "  sentence_counts = []\n",
        "  count = 0\n",
        "\n",
        "  while(idx < N):\n",
        "    if(topic_list[idx] == 1):\n",
        "      count += 1\n",
        "\n",
        "    idx += 1\n",
        "    \n",
        "  return int(round(N/count))\n",
        "\n",
        "# evaluate_pk\n",
        "# Evaluates PK\n",
        "def evaluate_pk(pred, act, k=5):\n",
        "  idx = k\n",
        "  miss_count = 0\n",
        "  measurement = 0\n",
        "\n",
        "  while (idx+k) < len(act):\n",
        "    topic_change_pred = False\n",
        "    topic_change_act = False\n",
        "\n",
        "    #Checking if there is a topic change - not including the first index\n",
        "    if sum(pred[idx-(k-1):idx+k]) >= 1:\n",
        "      topic_change_pred = True\n",
        "    if sum(act[idx-(k-1):idx+k]) >= 1:\n",
        "      topic_change_act = True\n",
        "\n",
        "    if topic_change_pred != topic_change_act:\n",
        "      miss_count += 1.0\n",
        "\n",
        "    measurement += 1.0\n",
        "    idx += 1\n",
        "\n",
        "  # print(miss_count)\n",
        "  # print(measurement)\n",
        "  pk = miss_count/measurement\n",
        "\n",
        "  return pk\n",
        "\n",
        "# evaluate_pk\n",
        "# Evaluates WD\n",
        "def evaluate_wd(pred, act, k=5):\n",
        "  idx = k\n",
        "  N = len(act)\n",
        "  count = 0\n",
        "\n",
        "  while (idx+k) < N:\n",
        "    # print(pred[idx-(k-1):idx+k])\n",
        "    sum_pred = sum(pred[idx-(k):idx+k])\n",
        "    sum_act = sum(act[idx-(k):idx+k])\n",
        "\n",
        "    #adds a count only if the number of boundaries is greater than 0\n",
        "    if abs(sum_pred - sum_act) > 0:\n",
        "      count += 1\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "  # print(miss_count)\n",
        "  # print(measurement)\n",
        "  wd = (1/(N-k))*count\n",
        "\n",
        "  return wd\n",
        "\n",
        "# get_meeting_sentences:\n",
        "# retrieves specific sentences from the transcripts_list\n",
        "def get_meeting_sentences(embedding_name=\"\", S_list=[], T_list=[], Y_list=[], transcripts_list=[]):\n",
        "  for transcript_idx, transcript in enumerate(transcripts_list):\n",
        "    if transcript == embedding_name:\n",
        "      # Convert Y in Integers. This happens\n",
        "      Y_to_convert = Y_list[transcript_idx]\n",
        "      Y_return = []\n",
        "      for Y_item in Y_to_convert:\n",
        "        Y_return.append(int(Y_item))\n",
        "      return S_list[transcript_idx], T_list[transcript_idx], Y_return, transcript\n",
        "\n",
        "# cos_sim:\n",
        "# Calculates cosine similarity between two vectors\n",
        "def cos_sim(a,b):\n",
        "  return dot(a, b)/(norm(a)*norm(b))\n",
        "\n",
        "# estimate_total:\n",
        "# Estimates total ETA to finish embeddings\n",
        "def estimate_total(S_list, done_embeddings, emb_speed):\n",
        "  # Inputs: S_list, and list of done embeddings, embedding speed\n",
        "  # Returns ETA for completion.\n",
        "  total_ETA = 0\n",
        "  total_words_to_embed = 0\n",
        "  for idx, sentences_to_embed in enumerate(S_list):\n",
        "    transcript_to_do = transcripts_list[idx]\n",
        "    if transcript_to_do in done_embeddings:\n",
        "      continue\n",
        "    else:\n",
        "      for sentence_to_embed in sentences_to_embed:\n",
        "        total_words_to_embed = total_words_to_embed + len(sentence_to_embed.split())\n",
        "  total_ETA = total_words_to_embed/emb_speed\n",
        "  return total_ETA\n",
        "\n",
        "# get_done_embeddings:\n",
        "# Searches all embeddings done in a folder.\n",
        "# Inputs: Embeddings Path, transcriptions_list, z_calculation\n",
        "# Returns List of transcript names that have embeddings stored in file\n",
        "def get_done_embeddings(embeddings_path):\n",
        "  done_embeddings = []\n",
        "  embedding_name = \"\"\n",
        "  embeddings_path = embeddings_path\n",
        "  \n",
        "  if z_partition_dataset == \"all\":\n",
        "    transcripts_list_z = transcripts_list\n",
        "  else:\n",
        "    z_partition_dataset_path = os.path.join(dataset_path, \"ep_splits.json\")\n",
        "    with open(z_partition_dataset_path) as f:\n",
        "      z_partition_dataset_json = json.load(f)\n",
        "    transcripts_list_z = z_partition_dataset_json[z_partition_dataset]\n",
        "\n",
        "  for embeddingsPath, embeddingsDname, embedddingsFname in os.walk(os.path.join(embeddings_path)):\n",
        "    for embeddings_name in embedddingsFname:\n",
        "      if embeddings_name.split(\".\")[-1] == \"pt\" or embeddings_name.split(\".\")[-1] == \"npy\":\n",
        "        embeddings_name = embeddings_name.replace(\".pt\",\"\")\n",
        "        embeddings_name = embeddings_name.replace(\".npy\",\"\")\n",
        "        if embeddings_name not in transcripts_list_z:\n",
        "          continue\n",
        "        done_embeddings.append(embeddings_name)\n",
        "    break\n",
        "  return done_embeddings\n",
        "\n",
        "# get_done_metrics:\n",
        "# Searches all metrics done in a csv file.\n",
        "def get_done_metrics(metric_results_filename_path=\"\",\n",
        "                     Y_hat_list_filename_path=\"\", \n",
        "                     T_hat_list_filename_path=\"\",\n",
        "                     sims_list_filename_path=\"\"):\n",
        "  with open(metric_results_filename_path, 'r+', encoding='UTF8', newline='') as f:\n",
        "    done_metrics = []\n",
        "    PK_metrics = []\n",
        "    WD_metrics = []\n",
        "    Y_hat_list = []\n",
        "    T_hat_list = []\n",
        "    csv_reader = csv.reader(f, delimiter=',')\n",
        "    line_count = 0\n",
        "    for row_idx, row in enumerate(csv_reader):\n",
        "      done_metrics.append(row[1])\n",
        "      PK_metrics.append(float(row[2]))\n",
        "      WD_metrics.append(float(row[3]))\n",
        "  Y_hat_list = np.load(Y_hat_list_filename_path,allow_pickle=True).tolist()\n",
        "  T_hat_list = np.load(T_hat_list_filename_path,allow_pickle=True).tolist()\n",
        "  sims_list = np.load(sims_list_filename_path,allow_pickle=True).tolist()\n",
        "  return done_metrics, PK_metrics, WD_metrics, Y_hat_list, T_hat_list, sims_list\n",
        "\n",
        "# load_ami_dataset:\n",
        "# Loads Transcripts from .transcripts/ folder and converts them into\n",
        "# S:                list of M utterances S = {S_1,..., S_M}\n",
        "# T:                Underlying topic structure Ti ∈ [Sj , Sk]\n",
        "# Y:                Label sequence Y = {y1,.., yM} yi is binary indicates whether the utterance Si is the start of a new topic segment\n",
        "# S_List:           List of S_i (utterances) for the i-th transcript or meeting\n",
        "# T_List:           List of T_i (Topic changes tuples) for the i-th transcript or meeting\n",
        "# Y_List:           List of Y_i (Topic changes flat) for the i-th transcript or meeting\n",
        "# transcripts_list: List of transcript names. Meetings or video_id.\n",
        "def load_ami_dataset(transcript_path=\"\"):\n",
        "\n",
        "  # Initiate variables\n",
        "  S_list=[]\n",
        "  T_list = []\n",
        "  Y_list = []\n",
        "  transcripts_list=[]\n",
        "  meeting_transcripts=[]\n",
        "\n",
        "  # Reads JSON from Folder\n",
        "  try:\n",
        "    transcripts = []\n",
        "    meeting_transcripts = []\n",
        "    transcripts_list = []\n",
        "    for transcriptPath, transcriptDname, transcriptFname in os.walk(os.path.join(transcripts_path)):\n",
        "      for transcript_name in transcriptFname:\n",
        "        transcripts_list.append(transcript_name.replace(\".json\",\"\"))\n",
        "        transcript_path = os.path.join(transcripts_path,transcript_name)\n",
        "        with open(transcript_path) as f:\n",
        "          data = json.load(f)\n",
        "        meeting_transcripts.append(data)\n",
        "  except Exception as error:\n",
        "    print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" ---  Error Loading JSON files - \" + str(error))\n",
        "    return S_list, T_list, Y_list, transcripts_list\n",
        "\n",
        "  # Process data set to return Main Variables\n",
        "  try:\n",
        "    S = []                \n",
        "    S_list = []            \n",
        "    T = []\n",
        "    T_list = []            \n",
        "    Y = []            \n",
        "    Y_list = []\n",
        "    W_count = []\n",
        "    W_count_list = []\n",
        "    W_T_count = []\n",
        "    W_T_count_list = []\n",
        "    W_M_count = []\n",
        "\n",
        "    T_start = 0\n",
        "    T_prev = 0\n",
        "    T_end = 0\n",
        "    idx_prev = 0\n",
        "    vocabulary = set()\n",
        "    sentence_greater = []\n",
        "\n",
        "    for meeting_idx, meeting_transcript in enumerate(meeting_transcripts):\n",
        "      # Change this to get one big vector\n",
        "      S = []\n",
        "      T = []\n",
        "      Y = []\n",
        "      W_count = []\n",
        "      W_T_count = []\n",
        "      T_start = 0\n",
        "      T_prev = 0\n",
        "      T_end = 0\n",
        "      idx_prev = 0\n",
        "      meeting_word_count = 0\n",
        "\n",
        "      transcript_id = transcripts_list[meeting_idx]\n",
        "      # print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" ---  \" + str(transcript_id) + \" - Start Process\")\n",
        "      # Remove above to get one big vector\n",
        "      for topics_idx, topics in enumerate(meeting_transcript):\n",
        "        topic_word_count = 0\n",
        "        for sentence_idx, sentence in enumerate(topics['sentences']):\n",
        "          # Generate S Vector\n",
        "          sentence_text = sentence['text']\n",
        "          sentence_text = sentence_text.replace(\" . \",\". \")\n",
        "          sentence_text = sentence_text.replace(\" . \",\". \")\n",
        "          sentence_text = sentence_text.replace(\"[gap]\",\"\")\n",
        "          sentence_text = sentence_text.replace(\"[vocalsound]\",\"\")\n",
        "          sentence_text = sentence_text.replace(\"[disfmarker]\",\"\")\n",
        "          sentence_text = sentence_text.replace(\"[transformerror]\",\" \")\n",
        "          sentence_word_count = len(sentence_text.split())\n",
        "          topic_word_count = topic_word_count + sentence_word_count\n",
        "          meeting_word_count = meeting_word_count + sentence_word_count\n",
        "          W_count.append(sentence_word_count)\n",
        "          # print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" ---  \" + str(transcript_id) + \" - Topic: \" + str(topics['topic_idx']) + \" Sentence: \" + str(sentence_idx) + \" Word Count: \" + str(sentence_word_count))\n",
        "\n",
        "          # Check if Sentence over 512 Words\n",
        "          if sentence_word_count > 512:\n",
        "            print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" ---  Error wordcount over 512 \" + str(transcript_id) + \" - Topic: \"  + str(topics_idx) + \" title: \" + str(topics['topic_idx']) + \" Sentence: \" + str(sentence_idx) + \" Word Count: \" + str(sentence_word_count))\n",
        "            sentence_greater.append(sentence_text)\n",
        "          S.append(sentence_text)\n",
        "          # Generate T initial and T end \n",
        "          if sentence_idx == 0:\n",
        "            T_start = T_prev\n",
        "            Y.append(1)\n",
        "          else:\n",
        "            Y.append(0)\n",
        "\n",
        "          # Create Vocabulary set\n",
        "          for word in sentence_text.split():\n",
        "            vocabulary.add(word)\n",
        "        T_end = sentence_idx + T_prev\n",
        "        T.append((T_start,T_end))\n",
        "        T_prev = T_end + 1\n",
        "        W_T_count.append(topic_word_count)\n",
        "        # print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" ---  \" + str(transcript_id) + \" - Word count per topic: \" + str(topic_word_count) + \" Total Sentences: \" + str(len(S)) + \" Total sentence words: \" + str(len(W_count)) + \" Total topics: \" + str(len(T)))\n",
        "      S_list.append(S)\n",
        "      T_list.append(T)\n",
        "      Y_list.append(Y)\n",
        "      W_count_list.append(W_count)\n",
        "      W_T_count_list.append(W_T_count)\n",
        "      W_M_count.append(meeting_word_count)\n",
        "      # print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" ---  \" + str(transcript_id) + \" - Total Sentences: \" + str(len(S)) + \" Total Sentence word count: \" + str(len(W_count)) + \" Total topics: \" + str(len(T)) + \" Total topics word_count: \" + str(len(W_T_count)))\n",
        "    # test_sentenece = 25\n",
        "    # print(Y_list[test_sentenece])\n",
        "    # print(len(S_list[test_sentenece][0]))\n",
        "    # print(T_list[test_sentenece])\n",
        "    # print(sentence_greater)\n",
        "\n",
        "    # print(\"Total Topics for meeting 25: \" + str(len(meeting_transcripts[25])))\n",
        "    # print(\"Example of meeting: \" + str(meeting_transcripts[25]))\n",
        "    # print(\"Meeting name: \" + str(transcripts_list[25]))\n",
        "    # print(len(meeting_transcripts[:1]))\n",
        "    # print(len(meeting_transcripts[0]))\n",
        "\n",
        "    # index_test = 115\n",
        "    # print(len(S[index_test].split()))\n",
        "    # print(W_count[index_test])\n",
        "    # print(len(meeting_transcripts))\n",
        "    # print(len(W_M_count))\n",
        "\n",
        "    # index_test = 25\n",
        "    for meeting_idx, meeting_transcript in enumerate(meeting_transcripts):\n",
        "      meeting_word_count = 0\n",
        "      transcript_id = transcripts_list[meeting_idx]\n",
        "      # if meeting_idx != index_test:\n",
        "      #   continue\n",
        "      for topics_idx, topics in enumerate(meeting_transcript):\n",
        "        for sentence_idx, sentence in enumerate(topics['sentences']):\n",
        "          sentence_text = sentence['text']\n",
        "          sentence_text = sentence_text.replace(\" . \",\". \")\n",
        "          sentence_text = sentence_text.replace(\" . \",\". \")\n",
        "          sentence_text = sentence_text.replace(\"[gap]\",\"\")\n",
        "          sentence_text = sentence_text.replace(\"[vocalsound]\",\"\")\n",
        "          sentence_text = sentence_text.replace(\"[disfmarker]\",\"\")\n",
        "          sentence_text = sentence_text.replace(\"[transformerror]\",\" \")\n",
        "          sentence_word_count = len(sentence_text.split())\n",
        "          meeting_word_count = meeting_word_count + sentence_word_count\n",
        "      # print(meeting_word_count)\n",
        "    # print(W_M_count[index_test])\n",
        "  except Exception as error:\n",
        "    print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" ---  Error Processing AMI Dataset - \" + str(error))\n",
        "    return S_list, T_list, Y_list, transcripts_list\n",
        "\n",
        "  return S_list, T_list, Y_list, transcripts_list\n",
        "\n",
        "# load_youtube_dataset:\n",
        "# Loads csvs from .YouTube/ folder and converts them into\n",
        "# S:                list of M utterances S = {S_1,..., S_M}\n",
        "# T:                Underlying topic structure Ti ∈ [Sj , Sk]\n",
        "# Y:                Label sequence Y = {y1,.., yM} yi is binary indicates whether the utterance Si is the start of a new topic segment\n",
        "# S_List:           List of S_i (utterances) for the i-th transcript or meeting\n",
        "# T_List:           List of T_i (Topic changes tuples) for the i-th transcript or meeting\n",
        "# Y_List:           List of Y_i (Topic changes flat) for the i-th transcript or meeting\n",
        "# transcripts_list: List of transcript names. Meetings or video_id.\n",
        "def load_youtube_dataset(dataset_path=\"\", filename=\"\"):\n",
        "  # Initiate variables\n",
        "  S_list=[]\n",
        "  T_list = []\n",
        "  Y_list = []\n",
        "  transcripts_list=[]\n",
        "  meeting_transcripts=[]\n",
        "\n",
        "  # Reads CSV from Folder\n",
        "  try:\n",
        "    # filename = \"yt_small_spacy_dev.csv\"\n",
        "    # filename = \"yt_scripts_segments_yt_simple_110922.csv\"\n",
        "    csv_path = os.path.join(dataset_path,filename)\n",
        "    yt_pods = pd.read_pickle(csv_path)\n",
        "    # print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" --- Loaded CSV: \" + str(csv_path))\n",
        "  except Exception as error:\n",
        "    print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" ---  Error Loading csv from YouTube Dataset - \" + str(error))\n",
        "    return S_list, T_list, Y_list, transcripts_list\n",
        "\n",
        "  # Process data set to return Main Variables\n",
        "  try:\n",
        "    for video_idx, video_id in enumerate(yt_pods[\"Video_Id\"]):\n",
        "      transcripts_list.append(video_id)\n",
        "\n",
        "    for sentences_idx, sentences in enumerate(yt_pods[\"Sentence_Word_Lists\"]):\n",
        "      S=[]\n",
        "      for sentence_idx, sentence in enumerate(sentences):\n",
        "        sentence_text = sentence[0]\n",
        "        S.append(sentence_text)\n",
        "      S_size = len(S)\n",
        "      S_list.append(S)\n",
        "\n",
        "    for transcript_labels_tuple_idx, transcript_labels_tuple in enumerate(yt_pods[\"Transition_Labels_Tuple\"]):\n",
        "      T_list.append(transcript_labels_tuple)\n",
        "\n",
        "    for transcript_labels_idx, transcript_labels in enumerate(yt_pods[\"Transition_Labels\"]):\n",
        "      Y_list.append(transcript_labels)\n",
        "      \n",
        "    # print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" --- Processed Video: \" + str(video_id) + \" - Sentences: \" + str(S_size))\n",
        "  except Exception as error:\n",
        "    print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \" --- Error processing Video: \" + str(video_id) + \" - Index: \" +str(sentences_idx) + \" - \" + str(error))\n",
        "    return S_list, T_list, Y_list, transcripts_list\n",
        "  \n",
        "  return S_list, T_list, Y_list, transcripts_list\n",
        "\n",
        "# load_process_dataset:\n",
        "# Process all datasets, and returns main variables and\n",
        "# transcripts, daset path\n",
        "def load_process_dataset(dataset_name=\"\", filename=\"\"):\n",
        "  S_list=[]\n",
        "  T_list=[]\n",
        "  Y_list=[]\n",
        "  W_count_list=[]\n",
        "  meeting_transcripts = []\n",
        "  transcripts_list = []\n",
        "  dataset_path = \"\"\n",
        "  transcripts_path = \"\"\n",
        "  embeddings_path = \"\"\n",
        "  dataset_path = os.path.join(path,'data/' + dataset_name + \"/\")\n",
        "  transcripts_path = os.path.join(dataset_path,'transcripts/')\n",
        "  if dataset_name == \"AMIDataset\":\n",
        "    S_list, T_list, Y_list, transcripts_list = load_ami_dataset(transcripts_path)\n",
        "  elif dataset_name == \"YouTube\":\n",
        "    S_list, T_list, Y_list, transcripts_list = load_youtube_dataset(dataset_path=dataset_path,filename=filename)\n",
        "  return (S_list, T_list, Y_list, W_count_list), (meeting_transcripts, transcripts_list), (dataset_path, transcripts_path)\n",
        "\n",
        "def rand_baseline(Y):\n",
        "  #Get the number of topic changes within the starting text\n",
        "  topic_changes = [i for i, x in enumerate(Y) if x == 1]\n",
        "  n = len(topic_changes)\n",
        "  \n",
        "  #Random Baseline Structure\n",
        "  rand_list=[]\n",
        "\n",
        "  #Generate a list of random increments for n number of topics\n",
        "  for i in range(n):\n",
        "      rand_list.append(random.randint(0,len(Y)-1))\n",
        "\n",
        "  # print(\"True Topic List Index:\", topic_changes)\n",
        "  # print(\"True Topic Array:\", Y)\n",
        "\n",
        "  # print(\"\\nRandom List Index:\", rand_list)\n",
        "\n",
        "  Y_random = np.zeros(len(Y)).astype(int)\n",
        "\n",
        "  for i in rand_list:\n",
        "    Y_random[i] = 1\n",
        "\n",
        "  return list(Y_random)\n",
        "\n",
        "def even_baseline(Y):\n",
        "  #Even Baseline Structure\n",
        "\n",
        "  # number of even increments between topics\n",
        "  # Technically this should be the average utterances of each \"topic\"\n",
        "  n = int(average_sentences(Y))\n",
        "  Y_even = np.zeros(len(Y)).astype(int)\n",
        "\n",
        "  #Generate a list of x increments for n number of topics\n",
        "  idx = 0\n",
        "  count = 0\n",
        "  while (idx < len(Y_even)) and (count < n):\n",
        "    Y_even[idx] = 1\n",
        "    idx += n\n",
        "    count += 1\n",
        "\n",
        "  return list(Y_even)\n",
        "\n",
        "# Define None baseline calculation\n",
        "def none_baseline(Y):\n",
        "  listofzeros = [0] * len(Y)\n",
        "  return listofzeros\n",
        "\n",
        "#Mae calculation for all predictions\n",
        "def mae_std(y_true, y_pred):\n",
        "  # ep_ref_tc = tf.reduce_sum(np.array(y_true, dtype='int'), axis=1).numpy()\n",
        "  # ep_pred_tc = tf.reduce_sum(np.array(y_pred, dtype='int'), axis=1).numpy()\n",
        "  # ep_diff = np.abs(ep_ref_tc - ep_pred_tc)\n",
        "  # ep_rel_diff = ep_diff/ep_ref_tc\n",
        "  # mae_std = np.mean(ep_rel_diff)\n",
        "  \n",
        "  if len(y_true) != len(y_pred) or len(y_true) <= 1:\n",
        "    print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "        \" - Error calculating MAE. Y_hat_list size vs Y_list size\")\n",
        "    raise SystemExit\n",
        "  ep_rel_diff = []\n",
        "  for y_true_i_idx, y_true_i in enumerate(y_true):\n",
        "    # print(\"calculating MAE for: \" + str(y_true_i_idx + 1) + \" of \" + str(len(y_true)))\n",
        "    ep_ref_tc = np.sum(y_true_i)\n",
        "    ep_pred_tc = np.sum(y_pred[y_true_i_idx])\n",
        "    ep_diff = np.abs(ep_ref_tc - ep_pred_tc)\n",
        "    ep_rel_diff.append(round(ep_diff/ep_ref_tc,5))\n",
        "\n",
        "  mae_std_measure = np.mean(ep_rel_diff)\n",
        "  return mae_std_measure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VmqocXKD9FE",
        "outputId": "0f6f67fe-b454-4088-d31a-1e5239c42409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Transcripts path:            /content/drive/MyDrive/W266/project/nlp_podcast_segmentation/data/YouTube/transcripts/\n",
            "Dataset path:                /content/drive/MyDrive/W266/project/nlp_podcast_segmentation/data/YouTube/\n",
            "Numb of transcripts S_list:  3757\n",
            "Numb of Topics T_list:       3757\n",
            "Numb of Outputs Y_list:      3757\n",
            "Transcripts name:            vNhSCF9i8Qs\n",
            "Numb of sentences in Test    1167\n",
            "Numb of topics in Test       19\n",
            "Numb of Outputs in Test      1167\n"
          ]
        }
      ],
      "source": [
        "#@title Load Dataset\n",
        "(S_list, T_list, Y_list, W_count_list), (meeting_transcripts, transcripts_list), (dataset_path, transcripts_path) = load_process_dataset(dataset_name = dataset_name, filename = filename)\n",
        "\n",
        "# Print Test\n",
        "index_test = 3\n",
        "print(\"\\n\")\n",
        "print(\"Transcripts path:            \" + str(transcripts_path))\n",
        "print(\"Dataset path:                \" + str(dataset_path))\n",
        "print(\"Numb of transcripts S_list:  \" + str(len(S_list)))\n",
        "print(\"Numb of Topics T_list:       \" + str(len(T_list)))\n",
        "print(\"Numb of Outputs Y_list:      \" + str(len(Y_list)))\n",
        "print(\"Transcripts name:            \" + str(transcripts_list[index_test]))\n",
        "print(\"Numb of sentences in Test    \" + str(len(S_list[index_test])))\n",
        "print(\"Numb of topics in Test       \" + str(len(T_list[index_test])))\n",
        "print(\"Numb of Outputs in Test      \" + str(len(Y_list[index_test])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIAAMVsXpTgJ",
        "outputId": "bb6fa260-15cd-4c5f-bba3-136fa36f7c4f",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-04 01:57:57 - all-MiniLM-L6-v2-meanpooling-WS1-Z1.0-all - metrics_results_path folder not found. New folder created\n",
            "2022-12-04 01:57:57 - Reading embeddings in path: /content/drive/MyDrive/W266/project/nlp_podcast_segmentation/data/YouTube/embeddings/yt_scripts_segments_split_n5_111422/all-MiniLM-L6-v2-meanpooling/\n",
            "2022-12-04 01:57:57 - Total embeddings: 3757\n",
            "2022-12-04 01:57:57 - Reading metrics in path: /content/drive/MyDrive/W266/project/nlp_podcast_segmentation/data/YouTube/metrics_results/yt_scripts_segments_split_n5_111422/all-MiniLM-L6-v2-meanpooling-WS1-Z1.0-all/results_all-MiniLM-L6-v2-meanpooling.csv\n",
            "2022-12-04 01:57:57 - Error reading embeddings path: /content/drive/MyDrive/W266/project/nlp_podcast_segmentation/data/YouTube/metrics_results/yt_scripts_segments_split_n5_111422/all-MiniLM-L6-v2-meanpooling-WS1-Z1.0-all/results_all-MiniLM-L6-v2-meanpooling.csv\n",
            " - Error: [Errno 2] No such file or directory: '/content/drive/MyDrive/W266/project/nlp_podcast_segmentation/data/YouTube/metrics_results/yt_scripts_segments_split_n5_111422/all-MiniLM-L6-v2-meanpooling-WS1-Z1.0-all/results_all-MiniLM-L6-v2-meanpooling.csv'\n",
            "2022-12-04 01:57:58 - Z7XvAjX9cFQ - 1 of 3757 - PK: 0.56156 - WD: 0.85485 - T: 31 T_hat: 167\n",
            "2022-12-04 01:57:58 - 9Rl8ZxdcWyk - 2 of 3757 - PK: 0.52579 - WD: 0.7063 - T: 34 T_hat: 115\n",
            "2022-12-04 01:57:59 - UReacGL2yhs - 3 of 3757 - PK: 0.99744 - WD: 1.0 - T: 1 T_hat: 133\n",
            "2022-12-04 01:58:00 - Tt4lL9hg2Bo - 4 of 3757 - PK: 0.58031 - WD: 0.93782 - T: 19 T_hat: 155\n",
            "2022-12-04 01:58:00 - dT6w90v6Lkg - 5 of 3757 - PK: 0.5648 - WD: 0.88813 - T: 25 T_hat: 127\n",
            "2022-12-04 01:58:01 - UISph2Pz6EY - 6 of 3757 - PK: 0.47496 - WD: 0.66882 - T: 37 T_hat: 100\n",
            "2022-12-04 01:58:01 - qKK9IOwaN98 - 7 of 3757 - PK: 0.59372 - WD: 0.90983 - T: 24 T_hat: 167\n",
            "2022-12-04 01:58:02 - dGvMxhkA9ZU - 8 of 3757 - PK: 0.48414 - WD: 0.67279 - T: 29 T_hat: 98\n",
            "2022-12-04 01:58:02 - Nne1NzJBqcc - 9 of 3757 - PK: 0.56639 - WD: 0.79577 - T: 32 T_hat: 126\n",
            "2022-12-04 01:58:03 - 6PDJDsC99ps - 10 of 3757 - PK: 0.54201 - WD: 0.78591 - T: 36 T_hat: 125\n",
            "2022-12-04 01:58:04 - xFjPTuUHmUo - 11 of 3757 - PK: 0.49429 - WD: 0.68189 - T: 35 T_hat: 100\n",
            "2022-12-04 01:58:04 - H5KaYOE_r8I - 12 of 3757 - PK: 0.50437 - WD: 0.85393 - T: 24 T_hat: 136\n",
            "2022-12-04 01:58:05 - qORnGlxRUOg - 13 of 3757 - PK: 0.48321 - WD: 0.69963 - T: 25 T_hat: 76\n",
            "2022-12-04 01:58:05 - -RN53GIAHWA - 14 of 3757 - PK: 0.55873 - WD: 0.81559 - T: 37 T_hat: 149\n",
            "2022-12-04 01:58:06 - z9JiEs-VcBs - 15 of 3757 - PK: 0.64452 - WD: 0.87296 - T: 25 T_hat: 151\n",
            "2022-12-04 01:58:07 - cnaLFWxDL28 - 16 of 3757 - PK: 0.54474 - WD: 0.82237 - T: 24 T_hat: 123\n",
            "2022-12-04 01:58:08 - miuSZscUpP4 - 17 of 3757 - PK: 0.63629 - WD: 0.91046 - T: 32 T_hat: 195\n",
            "2022-12-04 01:58:08 - vXMaOuG2nY8 - 18 of 3757 - PK: 0.46392 - WD: 0.7284 - T: 26 T_hat: 90\n",
            "2022-12-04 01:58:09 - u39Oquw3Gx0 - 19 of 3757 - PK: 0.56443 - WD: 0.74742 - T: 16 T_hat: 61\n",
            "2022-12-04 01:58:09 - OMn_v58vbLE - 20 of 3757 - PK: 0.58658 - WD: 0.94455 - T: 23 T_hat: 170\n",
            "2022-12-04 01:58:10 - ecb4TWtCKa8 - 21 of 3757 - PK: 0.45614 - WD: 0.73538 - T: 35 T_hat: 116\n",
            "2022-12-04 01:58:11 - n0HbD5CCPlg - 22 of 3757 - PK: 0.59687 - WD: 0.96154 - T: 15 T_hat: 137\n",
            "2022-12-04 01:58:11 - zZSFxcTH420 - 23 of 3757 - PK: 0.54907 - WD: 0.94393 - T: 17 T_hat: 138\n",
            "2022-12-04 01:58:12 - SdzUku_uv70 - 24 of 3757 - PK: 0.51521 - WD: 0.69231 - T: 29 T_hat: 86\n",
            "2022-12-04 01:58:12 - 0wzZ_eawG4o - 25 of 3757 - PK: 0.52639 - WD: 0.8628 - T: 21 T_hat: 127\n",
            "2022-12-04 01:58:13 - K4QiW2c6P0Q - 26 of 3757 - PK: 0.59402 - WD: 0.85237 - T: 21 T_hat: 97\n",
            "2022-12-04 01:58:14 - UG3uMZMhfg8 - 27 of 3757 - PK: 0.54639 - WD: 0.81787 - T: 33 T_hat: 145\n",
            "2022-12-04 01:58:14 - jhBu5q0uOj4 - 28 of 3757 - PK: 0.51015 - WD: 0.67513 - T: 24 T_hat: 54\n",
            "2022-12-04 01:58:15 - ezZANoYSHtA - 29 of 3757 - PK: 0.56084 - WD: 0.90432 - T: 36 T_hat: 223\n",
            "2022-12-04 01:58:16 - T1XERg5q8cg - 30 of 3757 - PK: 0.48346 - WD: 0.73858 - T: 30 T_hat: 93\n",
            "2022-12-04 01:58:17 - flCjo5Wafdo - 31 of 3757 - PK: 0.60778 - WD: 0.94556 - T: 20 T_hat: 149\n",
            "2022-12-04 01:58:17 - 84ZcSwKkt44 - 32 of 3757 - PK: 0.537 - WD: 0.75712 - T: 26 T_hat: 81\n",
            "2022-12-04 01:58:18 - 5lh23kUxkTo - 33 of 3757 - PK: 0.63591 - WD: 0.99127 - T: 11 T_hat: 143\n",
            "2022-12-04 01:58:19 - HDqs_gc2fyQ - 34 of 3757 - PK: 0.65981 - WD: 0.97757 - T: 9 T_hat: 88\n",
            "2022-12-04 01:58:19 - JF0UrHOAcZM - 35 of 3757 - PK: 0.51543 - WD: 0.79771 - T: 37 T_hat: 151\n",
            "2022-12-04 01:58:20 - n4gVtz7ikuE - 36 of 3757 - PK: 0.53175 - WD: 0.75277 - T: 33 T_hat: 107\n",
            "2022-12-04 01:58:20 - pBDHTtYgTVU - 37 of 3757 - PK: 0.56 - WD: 0.72462 - T: 39 T_hat: 103\n",
            "2022-12-04 01:59:48 - bx8BtdLv8TA - 38 of 3757 - PK: 0.56012 - WD: 0.83768 - T: 31 T_hat: 167\n",
            "2022-12-04 02:00:17 - y-5gjGM7Jz0 - 39 of 3757 - PK: 0.49327 - WD: 0.66504 - T: 48 T_hat: 136\n",
            "2022-12-04 02:00:18 - IxfO5hsplJE - 40 of 3757 - PK: 0.50382 - WD: 0.67176 - T: 63 T_hat: 170\n",
            "2022-12-04 02:00:18 - eBGfzs7EM1I - 41 of 3757 - PK: 0.61583 - WD: 0.99667 - T: 17 T_hat: 196\n",
            "2022-12-04 02:00:18 - 0bJdPE9cLXI - 42 of 3757 - PK: 0.531 - WD: 0.80863 - T: 15 T_hat: 65\n",
            "2022-12-04 02:00:18 - l9JGr7QBpNs - 43 of 3757 - PK: 0.4789 - WD: 0.81319 - T: 19 T_hat: 96\n",
            "2022-12-04 02:00:18 - XTmwGP3hkCU - 44 of 3757 - PK: 0.50525 - WD: 0.73767 - T: 45 T_hat: 160\n",
            "2022-12-04 02:00:18 - bXXbyrKYgJw - 45 of 3757 - PK: 0.47087 - WD: 0.69606 - T: 36 T_hat: 103\n",
            "2022-12-04 02:00:18 - eoIWipBYe64 - 46 of 3757 - PK: 0.42989 - WD: 0.66711 - T: 40 T_hat: 118\n",
            "2022-12-04 02:00:19 - ip4kdEw-n5E - 47 of 3757 - PK: 0.44851 - WD: 0.53425 - T: 40 T_hat: 71\n",
            "2022-12-04 02:00:20 - 7O47cfAdtac - 48 of 3757 - PK: 0.50472 - WD: 0.74292 - T: 39 T_hat: 134\n",
            "2022-12-04 02:00:20 - f1u4ARSm1Kc - 49 of 3757 - PK: 0.49091 - WD: 0.81916 - T: 42 T_hat: 206\n",
            "2022-12-04 02:00:20 - FZ75T3djk-M - 50 of 3757 - PK: 0.57511 - WD: 0.95966 - T: 26 T_hat: 208\n",
            "2022-12-04 02:00:20 - YHny1Ce31W8 - 51 of 3757 - PK: 0.69048 - WD: 0.9932 - T: 13 T_hat: 159\n",
            "2022-12-04 02:00:21 - g5o30hCvhZ4 - 52 of 3757 - PK: 0.65859 - WD: 0.94747 - T: 12 T_hat: 82\n",
            "2022-12-04 02:00:21 - dKBKQgaRbXU - 53 of 3757 - PK: 0.45742 - WD: 0.66343 - T: 48 T_hat: 143\n",
            "2022-12-04 02:00:21 - mXukwHL-wRo - 54 of 3757 - PK: 0.54478 - WD: 0.72287 - T: 52 T_hat: 146\n",
            "2022-12-04 02:00:21 - iieQn73Wh9E - 55 of 3757 - PK: 0.4949 - WD: 0.74066 - T: 38 T_hat: 135\n",
            "2022-12-04 02:00:21 - 22sY7a-HxuA - 56 of 3757 - PK: 0.51634 - WD: 0.75693 - T: 29 T_hat: 107\n",
            "2022-12-04 02:00:22 - Oa28hZ-htc0 - 57 of 3757 - PK: 0.53725 - WD: 0.73444 - T: 55 T_hat: 170\n",
            "2022-12-04 02:00:22 - muPVL8piVbY - 58 of 3757 - PK: 0.55665 - WD: 0.92866 - T: 17 T_hat: 139\n",
            "2022-12-04 02:00:22 - NnxS24VDZqY - 59 of 3757 - PK: 0.55354 - WD: 0.91104 - T: 18 T_hat: 107\n",
            "2022-12-04 02:00:22 - kvPD0jIvnGI - 60 of 3757 - PK: 0.51172 - WD: 0.77434 - T: 46 T_hat: 173\n",
            "2022-12-04 02:00:22 - vubKIgQ6yPE - 61 of 3757 - PK: 0.47913 - WD: 0.69616 - T: 33 T_hat: 100\n",
            "2022-12-04 02:00:23 - QBWMgPmMzlw - 62 of 3757 - PK: 0.52632 - WD: 0.67368 - T: 20 T_hat: 46\n",
            "2022-12-04 02:00:23 - yK8lEJtBWEI - 63 of 3757 - PK: 0.48481 - WD: 0.69199 - T: 45 T_hat: 117\n",
            "2022-12-04 02:00:23 - vDIqzZ9Ehd4 - 64 of 3757 - PK: 0.50895 - WD: 0.74078 - T: 43 T_hat: 141\n",
            "2022-12-04 02:00:23 - HGzJHInAvjE - 65 of 3757 - PK: 0.53714 - WD: 0.73905 - T: 29 T_hat: 93\n",
            "2022-12-04 02:00:23 - cbh3SZQj9hs - 66 of 3757 - PK: 0.55216 - WD: 0.85623 - T: 21 T_hat: 128\n",
            "2022-12-04 02:00:23 - naZUAG-jxMw - 67 of 3757 - PK: 0.58674 - WD: 0.93762 - T: 14 T_hat: 85\n",
            "2022-12-04 02:00:24 - adKkta1m8Lk - 68 of 3757 - PK: 0.51321 - WD: 0.72556 - T: 16 T_hat: 47\n",
            "2022-12-04 02:00:24 - 87ogjh5dUgk - 69 of 3757 - PK: 0.45596 - WD: 0.72193 - T: 54 T_hat: 176\n",
            "2022-12-04 02:00:24 - nSO-x3RzUPk - 70 of 3757 - PK: 0.53125 - WD: 0.75163 - T: 37 T_hat: 127\n",
            "2022-12-04 02:00:24 - XnGMiC3pueo - 71 of 3757 - PK: 0.55694 - WD: 0.81139 - T: 48 T_hat: 177\n",
            "2022-12-04 02:00:25 - 2DnTzXDBFI4 - 72 of 3757 - PK: 0.48496 - WD: 0.77896 - T: 45 T_hat: 183\n",
            "2022-12-04 02:00:25 - uvUSZgTKbp8 - 73 of 3757 - PK: 0.58013 - WD: 0.84135 - T: 26 T_hat: 105\n",
            "2022-12-04 02:00:25 - KbYa7tyk5pk - 74 of 3757 - PK: 0.51823 - WD: 0.88398 - T: 23 T_hat: 142\n",
            "2022-12-04 02:00:25 - WDSVHRDpuiA - 75 of 3757 - PK: 0.60955 - WD: 0.93765 - T: 17 T_hat: 140\n",
            "2022-12-04 02:00:25 - cNbKPpS0q5E - 76 of 3757 - PK: 0.55935 - WD: 0.83094 - T: 42 T_hat: 186\n",
            "2022-12-04 02:00:26 - -E2amekl414 - 77 of 3757 - PK: 0.55338 - WD: 0.76027 - T: 49 T_hat: 168\n",
            "2022-12-04 02:00:26 - qSVY65oJSow - 78 of 3757 - PK: 0.55793 - WD: 0.66629 - T: 67 T_hat: 144\n",
            "2022-12-04 02:00:26 - YpoRCRnn3KU - 79 of 3757 - PK: 0.53182 - WD: 0.77072 - T: 38 T_hat: 146\n",
            "2022-12-04 02:00:26 - M8LR1mW3Om0 - 80 of 3757 - PK: 0.48901 - WD: 0.71429 - T: 40 T_hat: 130\n",
            "2022-12-04 02:00:27 - HRGCWBfmZro - 81 of 3757 - PK: 0.52888 - WD: 0.75 - T: 29 T_hat: 109\n",
            "2022-12-04 02:00:27 - Y88-IqXgsUE - 82 of 3757 - PK: 0.49901 - WD: 0.72167 - T: 29 T_hat: 84\n",
            "2022-12-04 02:00:28 - 28NH7qcB0L4 - 83 of 3757 - PK: 0.477 - WD: 0.71599 - T: 28 T_hat: 97\n",
            "2022-12-04 02:00:28 - LaNzWoll_RU - 84 of 3757 - PK: 0.53269 - WD: 0.80835 - T: 41 T_hat: 159\n",
            "2022-12-04 02:00:28 - ZCI1eskzsfE - 85 of 3757 - PK: 0.55571 - WD: 0.88446 - T: 41 T_hat: 227\n",
            "2022-12-04 02:00:28 - ZZNt6KjEimY - 86 of 3757 - PK: 0.5746 - WD: 0.729 - T: 37 T_hat: 103\n",
            "2022-12-04 02:00:29 - nXVNm-lFD5Q - 87 of 3757 - PK: 0.58676 - WD: 0.89612 - T: 23 T_hat: 154\n",
            "2022-12-04 02:00:29 - KgDbMFsB1P8 - 88 of 3757 - PK: 0.49775 - WD: 0.8006 - T: 23 T_hat: 117\n",
            "2022-12-04 02:00:29 - HAqUQ85vapU - 89 of 3757 - PK: 0.5673 - WD: 0.8916 - T: 31 T_hat: 188\n",
            "2022-12-04 02:00:29 - s3SkplnSXWI - 90 of 3757 - PK: 0.52102 - WD: 0.70955 - T: 45 T_hat: 125\n",
            "2022-12-04 02:00:30 - lTrnb2bIWzM - 91 of 3757 - PK: 0.51434 - WD: 0.72951 - T: 45 T_hat: 150\n",
            "2022-12-04 02:00:30 - Cdgn325FkEQ - 92 of 3757 - PK: 0.55497 - WD: 0.88586 - T: 22 T_hat: 145\n",
            "2022-12-04 02:00:30 - 3T11aQ9liak - 93 of 3757 - PK: 0.52496 - WD: 0.70396 - T: 33 T_hat: 91\n",
            "2022-12-04 02:00:30 - 8pMymGlDA8o - 94 of 3757 - PK: 0.55879 - WD: 0.83518 - T: 27 T_hat: 159\n",
            "2022-12-04 02:00:31 - JCtidmmJCT0 - 95 of 3757 - PK: 0.55004 - WD: 0.75022 - T: 50 T_hat: 173\n",
            "2022-12-04 02:00:31 - 9jRne24CgqE - 96 of 3757 - PK: 0.53554 - WD: 0.78514 - T: 60 T_hat: 204\n",
            "2022-12-04 02:00:31 - mF_sPZOGdIM - 97 of 3757 - PK: 0.46286 - WD: 0.61198 - T: 41 T_hat: 102\n",
            "2022-12-04 02:00:32 - EFZpm7qP4Sc - 98 of 3757 - PK: 0.50077 - WD: 0.83461 - T: 44 T_hat: 213\n",
            "2022-12-04 02:00:32 - PDLImgyvcKk - 99 of 3757 - PK: 0.56038 - WD: 0.92358 - T: 28 T_hat: 171\n",
            "2022-12-04 02:00:32 - g4HL8KZtJC0 - 100 of 3757 - PK: 0.52269 - WD: 0.74708 - T: 36 T_hat: 115\n",
            "2022-12-04 02:00:32 - ipJHRqNVi3I - 101 of 3757 - PK: 0.55362 - WD: 0.94595 - T: 26 T_hat: 186\n",
            "2022-12-04 02:00:33 - d6oM_pmfKas - 102 of 3757 - PK: 0.43216 - WD: 0.65159 - T: 29 T_hat: 86\n",
            "2022-12-04 02:00:33 - AQKDLKEIgVA - 103 of 3757 - PK: 0.50403 - WD: 0.68116 - T: 44 T_hat: 104\n",
            "2022-12-04 02:00:33 - RdSP3Gnu4WM - 104 of 3757 - PK: 0.48819 - WD: 0.77559 - T: 22 T_hat: 84\n",
            "2022-12-04 02:00:34 - cd5gCdl1dlk - 105 of 3757 - PK: 0.61376 - WD: 0.98457 - T: 15 T_hat: 117\n",
            "2022-12-04 02:00:34 - YWZVGymoIc8 - 106 of 3757 - PK: 0.43173 - WD: 0.65746 - T: 32 T_hat: 88\n",
            "2022-12-04 02:00:34 - 9sFVDRZbZTA - 107 of 3757 - PK: 0.53705 - WD: 0.96161 - T: 19 T_hat: 185\n",
            "2022-12-04 02:00:34 - X7GQ3hE7p9s - 108 of 3757 - PK: 0.54928 - WD: 0.9048 - T: 32 T_hat: 191\n",
            "2022-12-04 02:00:35 - qlbl5Fftfv0 - 109 of 3757 - PK: 0.45758 - WD: 0.61515 - T: 53 T_hat: 110\n",
            "2022-12-04 02:00:35 - Q9l8ziwgkkI - 110 of 3757 - PK: 0.59391 - WD: 0.9533 - T: 21 T_hat: 161\n",
            "2022-12-04 02:00:35 - anMMt0G7PhU - 111 of 3757 - PK: 0.4449 - WD: 0.56887 - T: 51 T_hat: 96\n",
            "2022-12-04 02:00:36 - xISXy9OZp3M - 112 of 3757 - PK: 0.50895 - WD: 0.78635 - T: 42 T_hat: 166\n",
            "2022-12-04 02:00:36 - DrlI8-vBHz0 - 113 of 3757 - PK: 0.47059 - WD: 0.84584 - T: 14 T_hat: 83\n",
            "2022-12-04 02:00:36 - gLSAqpGEmK0 - 114 of 3757 - PK: 0.57939 - WD: 0.79666 - T: 14 T_hat: 58\n",
            "2022-12-04 02:00:37 - uhy5j1fOl8c - 115 of 3757 - PK: 0.55307 - WD: 0.61281 - T: 33 T_hat: 53\n",
            "2022-12-04 02:00:37 - 5sKfCN9Bj5Y - 116 of 3757 - PK: 0.55918 - WD: 0.97513 - T: 18 T_hat: 172\n",
            "2022-12-04 02:00:37 - sar97QOJCPs - 117 of 3757 - PK: 0.53521 - WD: 0.7169 - T: 41 T_hat: 109\n",
            "2022-12-04 02:00:38 - 5CJVmV5iJeg - 118 of 3757 - PK: 0.64898 - WD: 0.9483 - T: 14 T_hat: 118\n",
            "2022-12-04 02:00:38 - 40R8GV1tjlk - 119 of 3757 - PK: 0.49891 - WD: 0.60784 - T: 73 T_hat: 152\n",
            "2022-12-04 02:00:38 - x9IZ_jtlq4w - 120 of 3757 - PK: 0.44444 - WD: 0.44444 - T: 7 T_hat: 5\n",
            "2022-12-04 02:00:38 - cRzDKj9iUsE - 121 of 3757 - PK: 0.55677 - WD: 0.69357 - T: 45 T_hat: 108\n",
            "2022-12-04 02:00:39 - 6BHiq44NjUM - 122 of 3757 - PK: 0.45882 - WD: 0.58824 - T: 48 T_hat: 98\n",
            "2022-12-04 02:00:39 - JYlhN24KhHQ - 123 of 3757 - PK: 0.42621 - WD: 0.60731 - T: 50 T_hat: 135\n",
            "2022-12-04 02:00:39 - vGLZ7RKKvxw - 124 of 3757 - PK: 0.4963 - WD: 0.75103 - T: 59 T_hat: 206\n",
            "2022-12-04 02:00:40 - F124Ffqcm48 - 125 of 3757 - PK: 0.50694 - WD: 0.73266 - T: 45 T_hat: 130\n",
            "2022-12-04 02:00:40 - JNuVgUuO04c - 126 of 3757 - PK: 0.41736 - WD: 0.46914 - T: 26 T_hat: 36\n",
            "2022-12-04 02:00:40 - h9k_DpA_aRU - 127 of 3757 - PK: 0.48218 - WD: 0.51883 - T: 51 T_hat: 84\n",
            "2022-12-04 02:00:41 - GmQFpvK1aYY - 128 of 3757 - PK: 0.49172 - WD: 0.66817 - T: 77 T_hat: 210\n",
            "2022-12-04 02:00:41 - 2qz8z8PIUAM - 129 of 3757 - PK: 0.55172 - WD: 0.55172 - T: 6 T_hat: 4\n",
            "2022-12-04 02:00:41 - PkBn_qivoNg - 130 of 3757 - PK: 0.41404 - WD: 0.52014 - T: 51 T_hat: 93\n",
            "2022-12-04 02:00:42 - 8rnXDlKIZeM - 131 of 3757 - PK: 0.58166 - WD: 0.73154 - T: 28 T_hat: 73\n",
            "2022-12-04 02:00:42 - 2SM0dBckTQY - 132 of 3757 - PK: 0.47826 - WD: 0.59289 - T: 27 T_hat: 44\n",
            "2022-12-04 02:00:42 - oVxeIWL_x9k - 133 of 3757 - PK: 0.49333 - WD: 0.5837 - T: 63 T_hat: 107\n",
            "2022-12-04 02:00:43 - rdu-412o494 - 134 of 3757 - PK: 0.39623 - WD: 0.49811 - T: 26 T_hat: 39\n",
            "2022-12-04 02:00:43 - gGg4Wyw93nA - 135 of 3757 - PK: 0.52544 - WD: 0.81657 - T: 39 T_hat: 143\n",
            "2022-12-04 02:00:43 - __ZDnukpOBQ - 136 of 3757 - PK: 0.45902 - WD: 0.45161 - T: 12 T_hat: 13\n",
            "2022-12-04 02:00:44 - UFTI_XUbROc - 137 of 3757 - PK: 0.60098 - WD: 0.857 - T: 31 T_hat: 158\n",
            "2022-12-04 02:00:44 - by45jsQx4-8 - 138 of 3757 - PK: 0.62794 - WD: 0.89627 - T: 22 T_hat: 109\n",
            "2022-12-04 02:00:44 - xGvixhTJ2XQ - 139 of 3757 - PK: 0.44167 - WD: 0.56757 - T: 37 T_hat: 74\n",
            "2022-12-04 02:00:45 - wjPviLJ-6sU - 140 of 3757 - PK: 0.53358 - WD: 0.83993 - T: 37 T_hat: 187\n",
            "2022-12-04 02:00:45 - xbSq479BluY - 141 of 3757 - PK: 0.57349 - WD: 0.82651 - T: 41 T_hat: 195\n",
            "2022-12-04 02:00:45 - G9agN6DKbJU - 142 of 3757 - PK: 0.44986 - WD: 0.6 - T: 27 T_hat: 62\n",
            "2022-12-04 02:00:46 - j_QkAz-b6jM - 143 of 3757 - PK: 0.54354 - WD: 0.74673 - T: 73 T_hat: 232\n",
            "2022-12-04 02:00:46 - BGhfa7QZeu0 - 144 of 3757 - PK: 0.52273 - WD: 0.65909 - T: 31 T_hat: 74\n",
            "2022-12-04 02:00:47 - DGvGLMEonEE - 145 of 3757 - PK: 0.57961 - WD: 0.86313 - T: 28 T_hat: 120\n",
            "2022-12-04 02:00:47 - 9Yco_D0u_88 - 146 of 3757 - PK: 0.62807 - WD: 0.80882 - T: 41 T_hat: 168\n",
            "2022-12-04 02:00:47 - 3Qzch9AOpTU - 147 of 3757 - PK: 0.52156 - WD: 0.65779 - T: 32 T_hat: 71\n",
            "2022-12-04 02:00:48 - xcbP8Hxjefk - 148 of 3757 - PK: 0.56133 - WD: 0.83576 - T: 37 T_hat: 165\n",
            "2022-12-04 02:00:48 - fVqw7bjNhG0 - 149 of 3757 - PK: 0.4606 - WD: 0.67037 - T: 54 T_hat: 147\n",
            "2022-12-04 02:00:48 - 2MgLAKL57B4 - 150 of 3757 - PK: 0.51027 - WD: 0.65812 - T: 39 T_hat: 93\n",
            "2022-12-04 02:00:49 - WSdNptzAc-c - 151 of 3757 - PK: 0.4792 - WD: 0.70451 - T: 63 T_hat: 184\n",
            "2022-12-04 02:00:49 - _4jj5M9KtUk - 152 of 3757 - PK: 0.53943 - WD: 0.78136 - T: 52 T_hat: 179\n",
            "2022-12-04 02:00:50 - R5H4yHu9WSo - 153 of 3757 - PK: 0.49564 - WD: 0.7938 - T: 38 T_hat: 160\n",
            "2022-12-04 02:00:50 - VD9wiMF4TxE - 154 of 3757 - PK: 0.58796 - WD: 0.93292 - T: 29 T_hat: 203\n",
            "2022-12-04 02:00:51 - RwIoVs_q-cU - 155 of 3757 - PK: 0.48371 - WD: 0.70195 - T: 35 T_hat: 94\n",
            "2022-12-04 02:00:51 - HbV5od8Obwo - 156 of 3757 - PK: 0.58979 - WD: 0.97364 - T: 23 T_hat: 186\n",
            "2022-12-04 02:00:51 - -I60bmHSV0c - 157 of 3757 - PK: 0.59208 - WD: 0.98284 - T: 22 T_hat: 253\n",
            "2022-12-04 02:00:52 - cMwUdZ7Se2I - 158 of 3757 - PK: 0.50996 - WD: 0.67799 - T: 57 T_hat: 146\n",
            "2022-12-04 02:00:52 - FnWry5yesf4 - 159 of 3757 - PK: 0.4593 - WD: 0.65116 - T: 77 T_hat: 184\n",
            "2022-12-04 02:00:53 - -phL3j6mq74 - 160 of 3757 - PK: 0.53515 - WD: 0.80063 - T: 34 T_hat: 157\n",
            "2022-12-04 02:00:53 - 7421ubxQURE - 161 of 3757 - PK: 0.48786 - WD: 0.65121 - T: 34 T_hat: 76\n",
            "2022-12-04 02:00:53 - qy31H3g4mtI - 162 of 3757 - PK: 0.57306 - WD: 0.92884 - T: 22 T_hat: 184\n",
            "2022-12-04 02:00:54 - 98RCgzaNPc0 - 163 of 3757 - PK: 0.50688 - WD: 0.65226 - T: 44 T_hat: 89\n",
            "2022-12-04 02:00:54 - --LPM_6JYIc - 164 of 3757 - PK: 0.61732 - WD: 0.96614 - T: 26 T_hat: 211\n",
            "2022-12-04 02:00:55 - kft5awpBucw - 165 of 3757 - PK: 0.4034 - WD: 0.59023 - T: 40 T_hat: 78\n",
            "2022-12-04 02:00:55 - pSJIy0Yy4Ec - 166 of 3757 - PK: 0.48462 - WD: 0.61546 - T: 81 T_hat: 173\n",
            "2022-12-04 02:00:56 - JKYl_6oJ-0o - 167 of 3757 - PK: 0.36204 - WD: 0.61863 - T: 37 T_hat: 100\n",
            "2022-12-04 02:00:56 - OiLAWWZtUmY - 168 of 3757 - PK: 0.44444 - WD: 0.46667 - T: 11 T_hat: 8\n",
            "2022-12-04 02:00:56 - jlv08qbRidg - 169 of 3757 - PK: 0.51394 - WD: 0.69821 - T: 54 T_hat: 163\n",
            "2022-12-04 02:00:57 - ml0r0cMznZU - 170 of 3757 - PK: 0.58056 - WD: 0.82097 - T: 17 T_hat: 60\n",
            "2022-12-04 02:00:57 - NhrIAD3o19A - 171 of 3757 - PK: 0.61827 - WD: 0.92885 - T: 23 T_hat: 174\n",
            "2022-12-04 02:00:58 - 0yg3QUpZcHI - 172 of 3757 - PK: 0.52608 - WD: 0.70748 - T: 27 T_hat: 70\n",
            "2022-12-04 02:00:58 - hBru_unrS-g - 173 of 3757 - PK: 0.48429 - WD: 0.64972 - T: 65 T_hat: 175\n",
            "2022-12-04 02:00:59 - VV-s-fpWxJo - 174 of 3757 - PK: 0.47307 - WD: 0.79625 - T: 17 T_hat: 70\n",
            "2022-12-04 02:00:59 - 6ViuzeysiZs - 175 of 3757 - PK: 0.47462 - WD: 0.639 - T: 79 T_hat: 192\n",
            "2022-12-04 02:01:00 - pvnXtc0_0AY - 176 of 3757 - PK: 0.51235 - WD: 0.68875 - T: 38 T_hat: 101\n",
            "2022-12-04 02:01:00 - R6uh4edLebw - 177 of 3757 - PK: 0.41935 - WD: 0.45161 - T: 9 T_hat: 7\n",
            "2022-12-04 02:01:01 - FndlmpAxZ2s - 178 of 3757 - PK: 0.51649 - WD: 0.82092 - T: 43 T_hat: 182\n",
            "2022-12-04 02:01:01 - EmGkPDmpSgg - 179 of 3757 - PK: 0.58626 - WD: 0.92506 - T: 27 T_hat: 218\n",
            "2022-12-04 02:01:02 - DFeb1QBog8w - 180 of 3757 - PK: 0.58157 - WD: 0.91747 - T: 24 T_hat: 168\n",
            "2022-12-04 02:01:02 - 2z102tsZ67Q - 181 of 3757 - PK: 0.53793 - WD: 0.81149 - T: 20 T_hat: 69\n",
            "2022-12-04 02:01:02 - t5KdnEN4fAc - 182 of 3757 - PK: 0.48775 - WD: 0.70824 - T: 51 T_hat: 135\n",
            "2022-12-04 02:01:03 - xUFktvbCSPg - 183 of 3757 - PK: 0.38603 - WD: 0.53945 - T: 42 T_hat: 89\n",
            "2022-12-04 02:01:03 - 99L_zv8bNSE - 184 of 3757 - PK: 0.56401 - WD: 0.72635 - T: 61 T_hat: 177\n",
            "2022-12-04 02:01:04 - Wz9pCfHBVCM - 185 of 3757 - PK: 0.5641 - WD: 0.58974 - T: 10 T_hat: 8\n",
            "2022-12-04 02:01:04 - V1gOvPuJsds - 186 of 3757 - PK: 0.51712 - WD: 0.71763 - T: 33 T_hat: 93\n",
            "2022-12-04 02:01:05 - 6fEH_3HrGtg - 187 of 3757 - PK: 0.46065 - WD: 0.59028 - T: 35 T_hat: 74\n",
            "2022-12-04 02:01:05 - HjYW_CZk5RU - 188 of 3757 - PK: 0.56305 - WD: 0.75249 - T: 47 T_hat: 142\n",
            "2022-12-04 02:01:06 - rXoWyGfsNuY - 189 of 3757 - PK: 0.51163 - WD: 0.61628 - T: 34 T_hat: 61\n",
            "2022-12-04 02:01:06 - jYhX9LhTyis - 190 of 3757 - PK: 0.42951 - WD: 0.52787 - T: 26 T_hat: 50\n",
            "2022-12-04 02:01:07 - psxN8L3kD2w - 191 of 3757 - PK: 0.5212 - WD: 0.84289 - T: 30 T_hat: 170\n",
            "2022-12-04 02:01:07 - 6XgofT-pQ1w - 192 of 3757 - PK: 0.39693 - WD: 0.67632 - T: 30 T_hat: 100\n",
            "2022-12-04 02:01:08 - qLrav3Py12I - 193 of 3757 - PK: 0.52703 - WD: 0.82432 - T: 39 T_hat: 170\n",
            "2022-12-04 02:01:08 - nq1FMW14gD0 - 194 of 3757 - PK: 0.47742 - WD: 0.6086 - T: 43 T_hat: 80\n",
            "2022-12-04 02:01:09 - myOU2-aXGEI - 195 of 3757 - PK: 0.52115 - WD: 0.70532 - T: 33 T_hat: 114\n",
            "2022-12-04 02:01:09 - j1fMWsAQrEk - 196 of 3757 - PK: 0.51082 - WD: 0.75613 - T: 36 T_hat: 117\n",
            "2022-12-04 02:01:11 - M7UB1MCVH-o - 197 of 3757 - PK: 0.53918 - WD: 0.814 - T: 32 T_hat: 158\n",
            "2022-12-04 02:01:11 - nxGgmxph9wg - 198 of 3757 - PK: 0.5 - WD: 0.68605 - T: 28 T_hat: 67\n",
            "2022-12-04 02:01:12 - T16En55Sf0c - 199 of 3757 - PK: 0.44872 - WD: 0.5812 - T: 24 T_hat: 40\n",
            "2022-12-04 02:01:12 - XbFbHADE_bI - 200 of 3757 - PK: 0.55728 - WD: 0.81115 - T: 34 T_hat: 153\n",
            "2022-12-04 02:01:13 - xHzv5vRGdig - 201 of 3757 - PK: 0.52836 - WD: 0.75243 - T: 25 T_hat: 102\n",
            "2022-12-04 02:01:13 - BTWjpIEh8Fo - 202 of 3757 - PK: 0.55892 - WD: 0.6734 - T: 17 T_hat: 44\n",
            "2022-12-04 02:01:14 - 2f87sEhn1jc - 203 of 3757 - PK: 0.4 - WD: 0.56305 - T: 26 T_hat: 62\n",
            "2022-12-04 02:01:14 - 0jRsfKvjHho - 204 of 3757 - PK: 0.50054 - WD: 0.68512 - T: 58 T_hat: 150\n",
            "2022-12-04 02:01:15 - 4W8ks4J7FLY - 205 of 3757 - PK: 0.40726 - WD: 0.50403 - T: 20 T_hat: 32\n",
            "2022-12-04 02:01:15 - gfPHy1KliRg - 206 of 3757 - PK: 0.56318 - WD: 0.76895 - T: 25 T_hat: 84\n",
            "2022-12-04 02:01:16 - tAxbGwjgj4g - 207 of 3757 - PK: 0.47467 - WD: 0.55319 - T: 40 T_hat: 64\n",
            "2022-12-04 02:01:16 - IPqlSdjd_VQ - 208 of 3757 - PK: 0.58104 - WD: 0.79396 - T: 28 T_hat: 120\n",
            "2022-12-04 02:01:17 - W4GmDoC3FEA - 209 of 3757 - PK: 0.51475 - WD: 0.67828 - T: 23 T_hat: 58\n",
            "2022-12-04 02:01:17 - 9qOcC4WtQ0o - 210 of 3757 - PK: 0.53918 - WD: 0.68652 - T: 28 T_hat: 57\n",
            "2022-12-04 02:01:18 - R1RiDezX_Kk - 211 of 3757 - PK: 0.48429 - WD: 0.63216 - T: 38 T_hat: 82\n",
            "2022-12-04 02:01:18 - b2XSLFRMVyQ - 212 of 3757 - PK: 0.47222 - WD: 0.62558 - T: 38 T_hat: 104\n",
            "2022-12-04 02:01:19 - ugDSFgWCx8E - 213 of 3757 - PK: 0.46383 - WD: 0.60851 - T: 32 T_hat: 73\n",
            "2022-12-04 02:01:19 - 2gDLIvQstu4 - 214 of 3757 - PK: 0.61422 - WD: 0.88057 - T: 31 T_hat: 170\n",
            "2022-12-04 02:01:20 - TytU4MM_HvQ - 215 of 3757 - PK: 0.57692 - WD: 0.67832 - T: 24 T_hat: 47\n",
            "2022-12-04 02:01:20 - 1HgWchZjzQQ - 216 of 3757 - PK: 0.54279 - WD: 0.7241 - T: 44 T_hat: 130\n",
            "2022-12-04 02:01:21 - u1VuhB28HXQ - 217 of 3757 - PK: 0.56803 - WD: 0.7674 - T: 31 T_hat: 100\n",
            "2022-12-04 02:01:21 - IToqBjrdCAI - 218 of 3757 - PK: 0.5861 - WD: 0.80866 - T: 34 T_hat: 154\n",
            "2022-12-04 02:01:22 - 2IC6FOwKHo0 - 219 of 3757 - PK: 0.46429 - WD: 0.58333 - T: 24 T_hat: 53\n",
            "2022-12-04 02:01:22 - V0xJ9ZqxY_Q - 220 of 3757 - PK: 0.54991 - WD: 0.82684 - T: 36 T_hat: 174\n",
            "2022-12-04 02:01:23 - _1cjGFfqgRI - 221 of 3757 - PK: 0.53199 - WD: 0.76051 - T: 27 T_hat: 100\n",
            "2022-12-04 02:01:23 - _fgr_oNA9Z8 - 222 of 3757 - PK: 0.55678 - WD: 0.79418 - T: 43 T_hat: 164\n",
            "2022-12-04 02:01:24 - oJYnu5i5n3Y - 223 of 3757 - PK: 0.48041 - WD: 0.71959 - T: 27 T_hat: 82\n",
            "2022-12-04 02:01:24 - TnF69kXA9h0 - 224 of 3757 - PK: 0.46833 - WD: 0.75679 - T: 34 T_hat: 145\n",
            "2022-12-04 02:01:25 - RWS0ehhYVMw - 225 of 3757 - PK: 0.55398 - WD: 0.91504 - T: 34 T_hat: 197\n",
            "2022-12-04 02:01:26 - wo9KSvpw8ak - 226 of 3757 - PK: 0.47921 - WD: 0.75492 - T: 21 T_hat: 72\n",
            "2022-12-04 02:01:26 - 63VNIRegpHo - 227 of 3757 - PK: 0.53032 - WD: 0.66944 - T: 58 T_hat: 131\n",
            "2022-12-04 02:01:27 - bZ8OEUZgyDw - 228 of 3757 - PK: 0.40265 - WD: 0.58407 - T: 14 T_hat: 37\n",
            "2022-12-04 02:01:27 - bRFQ-JVlr-s - 229 of 3757 - PK: 0.46708 - WD: 0.66353 - T: 61 T_hat: 148\n",
            "2022-12-04 02:01:28 - wOhQMYTIvKc - 230 of 3757 - PK: 0.49653 - WD: 0.70139 - T: 13 T_hat: 46\n",
            "2022-12-04 02:01:28 - NSuX73SuhL0 - 231 of 3757 - PK: 0.46992 - WD: 0.723 - T: 46 T_hat: 172\n",
            "2022-12-04 02:01:29 - 4fwtPcu1Cgg - 232 of 3757 - PK: 0.43539 - WD: 0.59551 - T: 28 T_hat: 59\n",
            "2022-12-04 02:01:29 - usSA15cHBMM - 233 of 3757 - PK: 0.45045 - WD: 0.55856 - T: 11 T_hat: 19\n",
            "2022-12-04 02:01:30 - Bu5dolW5_70 - 234 of 3757 - PK: 0.59625 - WD: 0.89594 - T: 28 T_hat: 166\n",
            "2022-12-04 02:01:31 - 5WzGCvh7rEU - 235 of 3757 - PK: 0.51568 - WD: 0.80427 - T: 33 T_hat: 128\n",
            "2022-12-04 02:01:31 - qutVvjg7Wik - 236 of 3757 - PK: 0.46548 - WD: 0.68327 - T: 75 T_hat: 236\n",
            "2022-12-04 02:01:32 - hwyaUlrxWD0 - 237 of 3757 - PK: 0.48653 - WD: 0.65452 - T: 38 T_hat: 102\n",
            "2022-12-04 02:01:32 - zM1xIzdUxgY - 238 of 3757 - PK: 0.5 - WD: 0.66192 - T: 41 T_hat: 94\n",
            "2022-12-04 02:01:33 - nBxRQtfv7dM - 239 of 3757 - PK: 0.52252 - WD: 0.68168 - T: 40 T_hat: 112\n",
            "2022-12-04 02:01:33 - nYByLWEVMB8 - 240 of 3757 - PK: 0.50858 - WD: 0.77223 - T: 32 T_hat: 97\n",
            "2022-12-04 02:01:34 - vPrwe1KbUoA - 241 of 3757 - PK: 0.50239 - WD: 0.7327 - T: 39 T_hat: 129\n",
            "2022-12-04 02:01:35 - J2uW03lLhTo - 242 of 3757 - PK: 0.47673 - WD: 0.59155 - T: 54 T_hat: 111\n",
            "2022-12-04 02:01:35 - -Z3IoLsO5OM - 243 of 3757 - PK: 0.4 - WD: 0.46667 - T: 4 T_hat: 4\n",
            "2022-12-04 02:01:36 - 9EQJtXmS1jE - 244 of 3757 - PK: 0.49317 - WD: 0.71293 - T: 52 T_hat: 157\n",
            "2022-12-04 02:01:36 - MoAwKZ_fIkk - 245 of 3757 - PK: 0.45698 - WD: 0.60612 - T: 41 T_hat: 90\n",
            "2022-12-04 02:01:37 - lkkhOx_-lYY - 246 of 3757 - PK: 0.58791 - WD: 0.91169 - T: 30 T_hat: 195\n",
            "2022-12-04 02:01:37 - 2RKC2skIhgw - 247 of 3757 - PK: 0.46352 - WD: 0.63734 - T: 29 T_hat: 81\n",
            "2022-12-04 02:01:38 - 9O4FarQ8UK0 - 248 of 3757 - PK: 0.59814 - WD: 0.78647 - T: 32 T_hat: 121\n",
            "2022-12-04 02:01:39 - RwD1aLo9uTo - 249 of 3757 - PK: 0.51781 - WD: 0.82952 - T: 27 T_hat: 129\n",
            "2022-12-04 02:01:39 - ENseaNm1eTM - 250 of 3757 - PK: 0.43239 - WD: 0.60377 - T: 45 T_hat: 101\n",
            "2022-12-04 02:01:40 - lI0L4vD6lyI - 251 of 3757 - PK: 0.33333 - WD: 0.375 - T: 5 T_hat: 6\n",
            "2022-12-04 02:01:40 - pD5Xf-iDDDY - 252 of 3757 - PK: 0.48496 - WD: 0.77699 - T: 29 T_hat: 97\n",
            "2022-12-04 02:01:41 - Mi2kJMsx-tk - 253 of 3757 - PK: 0.47042 - WD: 0.67183 - T: 40 T_hat: 112\n",
            "2022-12-04 02:01:42 - RDSQsdX6qeA - 254 of 3757 - PK: 0.51724 - WD: 0.51724 - T: 17 T_hat: 4\n",
            "2022-12-04 02:01:42 - lJiupHqLQec - 255 of 3757 - PK: 0.53939 - WD: 0.74909 - T: 38 T_hat: 129\n",
            "2022-12-04 02:01:43 - 7TeMBfsMXEc - 256 of 3757 - PK: 0.55339 - WD: 0.82422 - T: 30 T_hat: 129\n",
            "2022-12-04 02:01:43 - cg-pKokHqIY - 257 of 3757 - PK: 0.50565 - WD: 0.77868 - T: 24 T_hat: 98\n",
            "2022-12-04 02:01:44 - 16_SpHhWVag - 258 of 3757 - PK: 0.49258 - WD: 0.72233 - T: 44 T_hat: 172\n",
            "2022-12-04 02:01:45 - wue1UbK2uEo - 259 of 3757 - PK: 0.53704 - WD: 0.69877 - T: 49 T_hat: 122\n",
            "2022-12-04 02:01:45 - pAmOddi2RsQ - 260 of 3757 - PK: 0.47388 - WD: 0.62127 - T: 45 T_hat: 92\n",
            "2022-12-04 02:01:46 - 95WJe5mvSeg - 261 of 3757 - PK: 0.4478 - WD: 0.65197 - T: 22 T_hat: 68\n",
            "2022-12-04 02:01:46 - A4ql_Zh1mL0 - 262 of 3757 - PK: 0.45118 - WD: 0.73737 - T: 28 T_hat: 102\n",
            "2022-12-04 02:01:47 - -lZXb-f1Iuo - 263 of 3757 - PK: 0.53659 - WD: 0.53659 - T: 11 T_hat: 8\n",
            "2022-12-04 02:01:48 - Z-OiLAl53y4 - 264 of 3757 - PK: 0.45814 - WD: 0.59767 - T: 34 T_hat: 73\n",
            "2022-12-04 02:01:48 - rIh5S3cVJEs - 265 of 3757 - PK: 0.52481 - WD: 0.83488 - T: 47 T_hat: 207\n",
            "2022-12-04 02:01:49 - o6PCgc_KwzM - 266 of 3757 - PK: 0.57588 - WD: 0.72765 - T: 29 T_hat: 86\n",
            "2022-12-04 02:01:49 - fxl5W-5JKwU - 267 of 3757 - PK: 0.56437 - WD: 0.87011 - T: 34 T_hat: 154\n",
            "2022-12-04 02:01:50 - X5MlIjll_TE - 268 of 3757 - PK: 0.49369 - WD: 0.70631 - T: 30 T_hat: 106\n",
            "2022-12-04 02:01:51 - vAx-hL7e2T8 - 269 of 3757 - PK: 0.50698 - WD: 0.71648 - T: 40 T_hat: 129\n",
            "2022-12-04 02:01:51 - wpoTujBfH_M - 270 of 3757 - PK: 0.51412 - WD: 0.67042 - T: 19 T_hat: 57\n",
            "2022-12-04 02:01:52 - 9OAja4R5hG0 - 271 of 3757 - PK: 0.56946 - WD: 0.8707 - T: 28 T_hat: 120\n",
            "2022-12-04 02:01:53 - ZcpKfTBr2_k - 272 of 3757 - PK: 0.39406 - WD: 0.52174 - T: 45 T_hat: 79\n",
            "2022-12-04 02:01:53 - x4IA0BNzcuA - 273 of 3757 - PK: 0.57402 - WD: 0.80134 - T: 44 T_hat: 182\n",
            "2022-12-04 02:01:54 - v-IRa56pbWo - 274 of 3757 - PK: 0.5241 - WD: 0.68592 - T: 44 T_hat: 125\n",
            "2022-12-04 02:01:54 - z31gQMsUnKo - 275 of 3757 - PK: 0.52857 - WD: 0.70476 - T: 24 T_hat: 67\n",
            "2022-12-04 02:01:55 - RS55aKJBj94 - 276 of 3757 - PK: 0.41758 - WD: 0.60659 - T: 33 T_hat: 81\n",
            "2022-12-04 02:01:56 - n-PptaPVTBw - 277 of 3757 - PK: 0.55718 - WD: 0.80991 - T: 55 T_hat: 269\n",
            "2022-12-04 02:01:56 - ye8pPRVe7so - 278 of 3757 - PK: 0.5615 - WD: 0.79323 - T: 24 T_hat: 91\n",
            "2022-12-04 02:01:57 - xAmi8mZ81pI - 279 of 3757 - PK: 0.53897 - WD: 0.89587 - T: 29 T_hat: 183\n",
            "2022-12-04 02:01:58 - GymJgkR_-Ro - 280 of 3757 - PK: 0.49465 - WD: 0.80122 - T: 50 T_hat: 220\n",
            "2022-12-04 02:01:58 - ppdrAiMsiQY - 281 of 3757 - PK: 0.48688 - WD: 0.6691 - T: 44 T_hat: 104\n",
            "2022-12-04 02:01:59 - ZdJiawi-qP4 - 282 of 3757 - PK: 0.54002 - WD: 0.74671 - T: 44 T_hat: 161\n",
            "2022-12-04 02:02:00 - M10d5SU5vBY - 283 of 3757 - PK: 0.57233 - WD: 0.82547 - T: 21 T_hat: 103\n",
            "2022-12-04 02:02:00 - DRW6-Y5eUbg - 284 of 3757 - PK: 0.44017 - WD: 0.64316 - T: 34 T_hat: 86\n",
            "2022-12-04 02:02:01 - uikKwJBOSdc - 285 of 3757 - PK: 0.53231 - WD: 0.77462 - T: 60 T_hat: 219\n",
            "2022-12-04 02:02:02 - WyaBngiWf1w - 286 of 3757 - PK: 0.51707 - WD: 0.77912 - T: 42 T_hat: 153\n",
            "2022-12-04 02:02:02 - 1wNf4VLKzAA - 287 of 3757 - PK: 0.46868 - WD: 0.63538 - T: 61 T_hat: 149\n",
            "2022-12-04 02:02:03 - U0g0GDjr-es - 288 of 3757 - PK: 0.49562 - WD: 0.63636 - T: 38 T_hat: 86\n",
            "2022-12-04 02:02:04 - MwUP59EUIK4 - 289 of 3757 - PK: 0.44676 - WD: 0.57247 - T: 72 T_hat: 150\n",
            "2022-12-04 02:02:04 - afnFuIQ8I1Q - 290 of 3757 - PK: 0.4763 - WD: 0.77014 - T: 22 T_hat: 76\n",
            "2022-12-04 02:02:05 - x7PFrIW03I4 - 291 of 3757 - PK: 0.52513 - WD: 0.67593 - T: 55 T_hat: 133\n",
            "2022-12-04 02:02:06 - UUIlUoTTCag - 292 of 3757 - PK: 0.55936 - WD: 0.75252 - T: 25 T_hat: 72\n",
            "2022-12-04 02:02:07 - pBfvCuaOaso - 293 of 3757 - PK: 0.49376 - WD: 0.66475 - T: 63 T_hat: 163\n",
            "2022-12-04 02:02:07 - 4ZSJfQEDHPQ - 294 of 3757 - PK: 0.46774 - WD: 0.62903 - T: 30 T_hat: 71\n",
            "2022-12-04 02:02:08 - lEgfV3GainM - 295 of 3757 - PK: 0.51435 - WD: 0.69533 - T: 50 T_hat: 152\n",
            "2022-12-04 02:02:09 - r3nkeJGqirM - 296 of 3757 - PK: 0.49802 - WD: 0.75099 - T: 26 T_hat: 92\n",
            "2022-12-04 02:02:09 - mBUFb--qSF4 - 297 of 3757 - PK: 0.36364 - WD: 0.39744 - T: 11 T_hat: 13\n",
            "2022-12-04 02:02:11 - dVTzGSt9B0I - 298 of 3757 - PK: 0.5056 - WD: 0.78267 - T: 47 T_hat: 212\n",
            "2022-12-04 02:02:12 - HXdiCiZGk80 - 299 of 3757 - PK: 0.54505 - WD: 0.8257 - T: 28 T_hat: 109\n",
            "2022-12-04 02:02:12 - Am4qG8MXu7M - 300 of 3757 - PK: 0.52636 - WD: 0.70783 - T: 75 T_hat: 209\n",
            "2022-12-04 02:02:13 - e9zPwJQikQc - 301 of 3757 - PK: 0.55005 - WD: 0.80079 - T: 46 T_hat: 166\n",
            "2022-12-04 02:02:14 - fbC9sTqVzfA - 302 of 3757 - PK: 0.50957 - WD: 0.67225 - T: 31 T_hat: 66\n",
            "2022-12-04 02:02:14 - XiLaA7Vgndc - 303 of 3757 - PK: 0.44516 - WD: 0.64807 - T: 31 T_hat: 82\n",
            "2022-12-04 02:02:15 - 4hOLEoikx6w - 304 of 3757 - PK: 0.59574 - WD: 0.80229 - T: 29 T_hat: 96\n",
            "2022-12-04 02:02:16 - lrXT6aNmvkc - 305 of 3757 - PK: 0.49451 - WD: 0.67276 - T: 32 T_hat: 83\n",
            "2022-12-04 02:02:17 - 9xGTvdctb4A - 306 of 3757 - PK: 0.48963 - WD: 0.73767 - T: 48 T_hat: 159\n",
            "2022-12-04 02:02:17 - 7K9E7BY8_Ck - 307 of 3757 - PK: 0.48814 - WD: 0.68023 - T: 51 T_hat: 141\n",
            "2022-12-04 02:02:18 - QynBEzLt7Vo - 308 of 3757 - PK: 0.45325 - WD: 0.68994 - T: 54 T_hat: 145\n",
            "2022-12-04 02:02:19 - r8yFbUYrBxY - 309 of 3757 - PK: 0.47746 - WD: 0.63626 - T: 57 T_hat: 143\n",
            "2022-12-04 02:02:19 - BFZey1fR8VQ - 310 of 3757 - PK: 0.60563 - WD: 0.80684 - T: 21 T_hat: 72\n",
            "2022-12-04 02:02:20 - stpiHTkO1WQ - 311 of 3757 - PK: 0.57048 - WD: 0.77691 - T: 41 T_hat: 150\n",
            "2022-12-04 02:02:21 - OGCiuxGTqkU - 312 of 3757 - PK: 0.55769 - WD: 0.69231 - T: 28 T_hat: 86\n",
            "2022-12-04 02:02:22 - l0zIn-cHY68 - 313 of 3757 - PK: 0.58652 - WD: 0.8879 - T: 33 T_hat: 209\n",
            "2022-12-04 02:02:22 - raUhdsAAJN8 - 314 of 3757 - PK: 0.51876 - WD: 0.75856 - T: 26 T_hat: 109\n",
            "2022-12-04 02:02:23 - nOdOJRi3E1k - 315 of 3757 - PK: 0.5976 - WD: 0.94595 - T: 15 T_hat: 120\n",
            "2022-12-04 02:02:24 - 98ej3TyaZxo - 316 of 3757 - PK: 0.55414 - WD: 0.66454 - T: 34 T_hat: 76\n",
            "2022-12-04 02:02:25 - a4LQ0LxSNm4 - 317 of 3757 - PK: 0.47173 - WD: 0.69396 - T: 21 T_hat: 78\n",
            "2022-12-04 02:02:25 - czUPYUwPZSY - 318 of 3757 - PK: 0.48171 - WD: 0.65601 - T: 44 T_hat: 109\n",
            "2022-12-04 02:02:26 - n-T4LiaJvQ0 - 319 of 3757 - PK: 0.52047 - WD: 0.66374 - T: 24 T_hat: 61\n",
            "2022-12-04 02:02:27 - fj-zuFjtbv4 - 320 of 3757 - PK: 0.50492 - WD: 0.71582 - T: 57 T_hat: 172\n",
            "2022-12-04 02:02:28 - bFZNOJg_ZGE - 321 of 3757 - PK: 0.50267 - WD: 0.72242 - T: 60 T_hat: 189\n",
            "2022-12-04 02:02:29 - dAFLea9dLm8 - 322 of 3757 - PK: 0.4691 - WD: 0.70523 - T: 36 T_hat: 116\n",
            "2022-12-04 02:02:29 - j2u9C0QQYgw - 323 of 3757 - PK: 0.50443 - WD: 0.77468 - T: 73 T_hat: 267\n",
            "2022-12-04 02:02:30 - -7JTrLBD260 - 324 of 3757 - PK: 0.55804 - WD: 0.86495 - T: 37 T_hat: 190\n",
            "2022-12-04 02:02:31 - l_Ik2WSiJc4 - 325 of 3757 - PK: 0.42191 - WD: 0.49883 - T: 40 T_hat: 66\n",
            "2022-12-04 02:02:32 - 78okTa1GoWk - 326 of 3757 - PK: 0.44202 - WD: 0.62868 - T: 70 T_hat: 166\n",
            "2022-12-04 02:02:33 - LDixA4JFuMs - 327 of 3757 - PK: 0.49117 - WD: 0.72968 - T: 29 T_hat: 96\n",
            "2022-12-04 02:02:33 - Miw1QbRub9M - 328 of 3757 - PK: 0.5 - WD: 0.65111 - T: 33 T_hat: 72\n",
            "2022-12-04 02:02:34 - 3h-SsOrPG_Q - 329 of 3757 - PK: 0.53244 - WD: 0.72952 - T: 28 T_hat: 88\n",
            "2022-12-04 02:02:35 - Jv0igVNbfB4 - 330 of 3757 - PK: 0.56167 - WD: 0.68939 - T: 40 T_hat: 90\n",
            "2022-12-04 02:02:36 - PfNyzF6zrvE - 331 of 3757 - PK: 0.55977 - WD: 0.81025 - T: 38 T_hat: 176\n",
            "2022-12-04 02:02:37 - EVAssBV3Hgw - 332 of 3757 - PK: 0.44426 - WD: 0.53796 - T: 70 T_hat: 104\n",
            "2022-12-04 02:02:37 - s6YgpSzJNrg - 333 of 3757 - PK: 0.41379 - WD: 0.59852 - T: 26 T_hat: 65\n",
            "2022-12-04 02:02:38 - fMbblp2MaMg - 334 of 3757 - PK: 0.54116 - WD: 0.8079 - T: 37 T_hat: 151\n",
            "2022-12-04 02:02:39 - jeicCXFWpWI - 335 of 3757 - PK: 0.48907 - WD: 0.67789 - T: 65 T_hat: 169\n",
            "2022-12-04 02:02:40 - qdwQnoGx4VU - 336 of 3757 - PK: 0.43408 - WD: 0.6146 - T: 36 T_hat: 90\n",
            "2022-12-04 02:02:41 - NaUY5Kkkd1M - 337 of 3757 - PK: 0.64915 - WD: 0.91017 - T: 21 T_hat: 107\n",
            "2022-12-04 02:02:42 - My7UOX11DTQ - 338 of 3757 - PK: 0.5721 - WD: 0.87943 - T: 27 T_hat: 134\n",
            "2022-12-04 02:02:43 - LYAmNCAgoD4 - 339 of 3757 - PK: 0.48143 - WD: 0.66122 - T: 49 T_hat: 116\n",
            "2022-12-04 02:02:44 - uFWCItYNah8 - 340 of 3757 - PK: 0.53476 - WD: 0.7041 - T: 29 T_hat: 80\n",
            "2022-12-04 02:02:45 - 9CGduTEpTgw - 341 of 3757 - PK: 0.52385 - WD: 0.77064 - T: 54 T_hat: 193\n",
            "2022-12-04 02:02:46 - jhjY9JkKMmQ - 342 of 3757 - PK: 0.52457 - WD: 0.73019 - T: 50 T_hat: 153\n",
            "2022-12-04 02:02:47 - WM6f3_8v4j0 - 343 of 3757 - PK: 0.52662 - WD: 0.82902 - T: 28 T_hat: 118\n",
            "2022-12-04 02:02:47 - uKOJkc5J69E - 344 of 3757 - PK: 0.47942 - WD: 0.73868 - T: 27 T_hat: 89\n",
            "2022-12-04 02:02:48 - kPo06hB8-ks - 345 of 3757 - PK: 0.47048 - WD: 0.75295 - T: 43 T_hat: 162\n",
            "2022-12-04 02:02:49 - um2dJ95T6KM - 346 of 3757 - PK: 0.48421 - WD: 0.66526 - T: 35 T_hat: 87\n",
            "2022-12-04 02:02:50 - _dfJvBRPDKE - 347 of 3757 - PK: 0.45124 - WD: 0.59948 - T: 50 T_hat: 117\n",
            "2022-12-04 02:02:51 - AtFViBjx880 - 348 of 3757 - PK: 0.45269 - WD: 0.71138 - T: 47 T_hat: 145\n",
            "2022-12-04 02:02:51 - ceevhFrFg-o - 349 of 3757 - PK: 0.44626 - WD: 0.68925 - T: 18 T_hat: 70\n",
            "2022-12-04 02:02:52 - 1Cw9fwPNhcQ - 350 of 3757 - PK: 0.48035 - WD: 0.67587 - T: 40 T_hat: 111\n",
            "2022-12-04 02:02:53 - VKkO2y2kfIo - 351 of 3757 - PK: 0.5592 - WD: 0.8306 - T: 19 T_hat: 90\n",
            "2022-12-04 02:02:54 - q2WmwYqgbCg - 352 of 3757 - PK: 0.58235 - WD: 0.76765 - T: 17 T_hat: 55\n",
            "2022-12-04 02:02:56 - BN50kU78f3s - 353 of 3757 - PK: 0.60545 - WD: 0.93273 - T: 14 T_hat: 96\n",
            "2022-12-04 02:02:56 - _PMjEkjFjvk - 354 of 3757 - PK: 0.54071 - WD: 0.8 - T: 23 T_hat: 83\n",
            "2022-12-04 02:02:57 - Vwb1dVVt0SE - 355 of 3757 - PK: 0.50388 - WD: 0.71124 - T: 25 T_hat: 77\n",
            "2022-12-04 02:02:58 - l9YVfucuzVM - 356 of 3757 - PK: 0.42958 - WD: 0.69708 - T: 58 T_hat: 188\n",
            "2022-12-04 02:02:59 - qCm2FJz69J4 - 357 of 3757 - PK: 0.58974 - WD: 0.8048 - T: 30 T_hat: 97\n",
            "2022-12-04 02:03:00 - zM-y-whjOZ8 - 358 of 3757 - PK: 0.51444 - WD: 0.72902 - T: 41 T_hat: 123\n",
            "2022-12-04 02:03:01 - EqsZHQeFl_8 - 359 of 3757 - PK: 0.48728 - WD: 0.72798 - T: 26 T_hat: 91\n",
            "2022-12-04 02:03:01 - QbtTK60LiMc - 360 of 3757 - PK: 0.49065 - WD: 0.80748 - T: 39 T_hat: 146\n",
            "2022-12-04 02:03:02 - tsdumAZv8pk - 361 of 3757 - PK: 0.47333 - WD: 0.67994 - T: 72 T_hat: 220\n",
            "2022-12-04 02:03:03 - ln-soHpT3CY - 362 of 3757 - PK: 0.48223 - WD: 0.74662 - T: 28 T_hat: 106\n",
            "2022-12-04 02:03:04 - pA9RkNwyt-w - 363 of 3757 - PK: 0.4943 - WD: 0.74271 - T: 40 T_hat: 125\n",
            "2022-12-04 02:03:05 - d2flSBtI7R4 - 364 of 3757 - PK: 0.50689 - WD: 0.73201 - T: 36 T_hat: 117\n",
            "2022-12-04 02:03:06 - 2_k9sJUmt5A - 365 of 3757 - PK: 0.473 - WD: 0.63931 - T: 33 T_hat: 76\n",
            "2022-12-04 02:03:07 - dvpn7ts0s-k - 366 of 3757 - PK: 0.49017 - WD: 0.85932 - T: 28 T_hat: 154\n",
            "2022-12-04 02:03:07 - cmaY5YUugHM - 367 of 3757 - PK: 0.49545 - WD: 0.67727 - T: 40 T_hat: 117\n",
            "2022-12-04 02:03:08 - mCyeQRBGKeM - 368 of 3757 - PK: 0.44747 - WD: 0.66019 - T: 27 T_hat: 82\n",
            "2022-12-04 02:03:09 - YiFtxVZ8Y8I - 369 of 3757 - PK: 0.4334 - WD: 0.59197 - T: 32 T_hat: 69\n",
            "2022-12-04 02:03:10 - h4_WWkyJYrw - 370 of 3757 - PK: 0.5618 - WD: 0.72051 - T: 38 T_hat: 98\n",
            "2022-12-04 02:03:11 - _Lfh6QS7i9U - 371 of 3757 - PK: 0.54707 - WD: 0.78241 - T: 65 T_hat: 218\n",
            "2022-12-04 02:03:12 - FDCix9isK4Q - 372 of 3757 - PK: 0.45969 - WD: 0.65912 - T: 45 T_hat: 111\n",
            "2022-12-04 02:03:13 - 4P1MiraXGj8 - 373 of 3757 - PK: 0.51259 - WD: 0.70529 - T: 43 T_hat: 121\n",
            "2022-12-04 02:03:14 - YkCEDgDP3MM - 374 of 3757 - PK: 0.52857 - WD: 0.75286 - T: 40 T_hat: 116\n",
            "2022-12-04 02:03:14 - W72tiwuhnbI - 375 of 3757 - PK: 0.45661 - WD: 0.64103 - T: 65 T_hat: 160\n",
            "2022-12-04 02:03:15 - XdOtjcMq_pU - 376 of 3757 - PK: 0.47761 - WD: 0.73321 - T: 27 T_hat: 87\n",
            "2022-12-04 02:03:16 - vAvtQ3Ytu_c - 377 of 3757 - PK: 0.50151 - WD: 0.59215 - T: 26 T_hat: 56\n",
            "2022-12-04 02:03:17 - 0YuFyadq844 - 378 of 3757 - PK: 0.41707 - WD: 0.55122 - T: 29 T_hat: 60\n",
            "2022-12-04 02:03:18 - HQLJNRCWCm4 - 379 of 3757 - PK: 0.41452 - WD: 0.72097 - T: 28 T_hat: 100\n",
            "2022-12-04 02:03:20 - hi2k5W3G_3M - 380 of 3757 - PK: 0.50853 - WD: 0.68443 - T: 57 T_hat: 158\n",
            "2022-12-04 02:03:21 - g0-6P9baUeU - 381 of 3757 - PK: 0.52696 - WD: 0.76225 - T: 37 T_hat: 141\n",
            "2022-12-04 02:03:22 - muMZ1XzLOp4 - 382 of 3757 - PK: 0.53015 - WD: 0.93763 - T: 12 T_hat: 91\n",
            "2022-12-04 02:03:22 - zwwhQKtLgWU - 383 of 3757 - PK: 0.54913 - WD: 0.90944 - T: 23 T_hat: 170\n",
            "2022-12-04 02:03:23 - scTGoHoXiFw - 384 of 3757 - PK: 0.59883 - WD: 0.99217 - T: 10 T_hat: 83\n",
            "2022-12-04 02:03:24 - ohYb69yW9Ig - 385 of 3757 - PK: 0.49154 - WD: 0.85507 - T: 40 T_hat: 202\n",
            "2022-12-04 02:03:25 - QUn47TrBvGw - 386 of 3757 - PK: 0.57219 - WD: 0.97331 - T: 11 T_hat: 108\n",
            "2022-12-04 02:03:26 - iBKvAQIw0LE - 387 of 3757 - PK: 0.54987 - WD: 0.9252 - T: 18 T_hat: 125\n",
            "2022-12-04 02:03:27 - 0QgF75fXpzE - 388 of 3757 - PK: 0.5506 - WD: 0.84734 - T: 15 T_hat: 94\n",
            "2022-12-04 02:03:28 - 6LDP_SyswNk - 389 of 3757 - PK: 0.59415 - WD: 0.91603 - T: 20 T_hat: 125\n",
            "2022-12-04 02:03:29 - oebxgrOowvw - 390 of 3757 - PK: 0.57808 - WD: 0.97674 - T: 11 T_hat: 106\n",
            "2022-12-04 02:03:30 - _WQnUPFQifY - 391 of 3757 - PK: 0.61558 - WD: 0.87356 - T: 28 T_hat: 118\n",
            "2022-12-04 02:03:31 - Ydx3vYuswF4 - 392 of 3757 - PK: 0.47626 - WD: 0.64156 - T: 42 T_hat: 106\n",
            "2022-12-04 02:03:32 - WVjws5iAzSw - 393 of 3757 - PK: 0.5815 - WD: 0.87912 - T: 12 T_hat: 70\n",
            "2022-12-04 02:03:32 - 86PNCm1x_Rc - 394 of 3757 - PK: 0.53686 - WD: 0.9 - T: 21 T_hat: 112\n",
            "2022-12-04 02:03:33 - Q0jMRTZxS3w - 395 of 3757 - PK: 0.53103 - WD: 0.86912 - T: 25 T_hat: 154\n",
            "2022-12-04 02:03:34 - J53zvAf-lc0 - 396 of 3757 - PK: 0.55126 - WD: 0.7916 - T: 25 T_hat: 95\n",
            "2022-12-04 02:03:35 - GHmEuHx1hLM - 397 of 3757 - PK: 0.58669 - WD: 0.90323 - T: 10 T_hat: 84\n",
            "2022-12-04 02:03:36 - tMvWhQ59j2c - 398 of 3757 - PK: 0.59008 - WD: 0.82031 - T: 17 T_hat: 66\n",
            "2022-12-04 02:03:37 - _wQSgkQOpY4 - 399 of 3757 - PK: 0.56009 - WD: 0.89342 - T: 22 T_hat: 143\n",
            "2022-12-04 02:03:38 - 3DyqItKAK3U - 400 of 3757 - PK: 0.60606 - WD: 0.90374 - T: 15 T_hat: 86\n",
            "2022-12-04 02:03:39 - KRXdk5ovEC4 - 401 of 3757 - PK: 0.58919 - WD: 0.92117 - T: 20 T_hat: 148\n",
            "2022-12-04 02:03:40 - eLF6zlNnf2g - 402 of 3757 - PK: 0.52079 - WD: 0.80088 - T: 19 T_hat: 85\n",
            "2022-12-04 02:03:41 - GkEfcEglf6Y - 403 of 3757 - PK: 0.53267 - WD: 0.89915 - T: 18 T_hat: 119\n",
            "2022-12-04 02:03:42 - 41GAqkWCElg - 404 of 3757 - PK: 0.50495 - WD: 0.79051 - T: 19 T_hat: 84\n",
            "2022-12-04 02:03:42 - tjrFfHpbY0I - 405 of 3757 - PK: 0.62674 - WD: 0.81597 - T: 22 T_hat: 93\n",
            "2022-12-04 02:03:43 - _QfxBxVWOFA - 406 of 3757 - PK: 0.58401 - WD: 0.80649 - T: 38 T_hat: 140\n",
            "2022-12-04 02:03:44 - DT1FCXuO7gY - 407 of 3757 - PK: 0.4803 - WD: 0.63227 - T: 39 T_hat: 85\n",
            "2022-12-04 02:03:45 - BfvN1fEnoI8 - 408 of 3757 - PK: 0.51075 - WD: 0.86918 - T: 13 T_hat: 98\n",
            "2022-12-04 02:03:46 - JEqJnpK5BWE - 409 of 3757 - PK: 0.60666 - WD: 1.0 - T: 8 T_hat: 118\n",
            "2022-12-04 02:03:47 - KjJ_E7qJanE - 410 of 3757 - PK: 0.55307 - WD: 0.82571 - T: 34 T_hat: 165\n",
            "2022-12-04 02:03:48 - rw-i_wCtn84 - 411 of 3757 - PK: 0.60442 - WD: 0.87149 - T: 15 T_hat: 85\n",
            "2022-12-04 02:03:49 - Wn3mcEYIphk - 412 of 3757 - PK: 0.52298 - WD: 0.77243 - T: 19 T_hat: 73\n",
            "2022-12-04 02:03:50 - Pfz_xc8WIlw - 413 of 3757 - PK: 0.57807 - WD: 0.93123 - T: 13 T_hat: 87\n",
            "2022-12-04 02:03:51 - s_7dcVKv-Pc - 414 of 3757 - PK: 0.50615 - WD: 0.77329 - T: 28 T_hat: 96\n",
            "2022-12-04 02:03:52 - ylSL1VxOxj0 - 415 of 3757 - PK: 0.58362 - WD: 0.93288 - T: 21 T_hat: 140\n",
            "2022-12-04 02:03:53 - bfVfmc6qa7Q - 416 of 3757 - PK: 0.50117 - WD: 0.78089 - T: 17 T_hat: 66\n",
            "2022-12-04 02:03:54 - gq8TbuA4GAM - 417 of 3757 - PK: 0.57293 - WD: 0.86662 - T: 45 T_hat: 252\n",
            "2022-12-04 02:03:55 - pT_MKHv4Cx8 - 418 of 3757 - PK: 0.52262 - WD: 0.79638 - T: 19 T_hat: 75\n",
            "2022-12-04 02:03:56 - gEFsDzmo8jU - 419 of 3757 - PK: 0.49899 - WD: 0.68474 - T: 22 T_hat: 71\n",
            "2022-12-04 02:03:56 - 43ESeqViVOY - 420 of 3757 - PK: 0.61395 - WD: 0.95659 - T: 18 T_hat: 109\n",
            "2022-12-04 02:03:58 - 9BGpdRK4wBk - 421 of 3757 - PK: 0.545 - WD: 0.7975 - T: 15 T_hat: 56\n",
            "2022-12-04 02:03:58 - HoNUxKQZ2Jc - 422 of 3757 - PK: 0.57808 - WD: 0.96443 - T: 16 T_hat: 125\n",
            "2022-12-04 02:03:59 - dH_5ef9NU1Q - 423 of 3757 - PK: 0.57163 - WD: 0.87393 - T: 22 T_hat: 120\n",
            "2022-12-04 02:04:00 - U9LPpZWnfUw - 424 of 3757 - PK: 0.60419 - WD: 1.0 - T: 9 T_hat: 125\n",
            "2022-12-04 02:04:01 - sNuUOImVABM - 425 of 3757 - PK: 0.99791 - WD: 1.0 - T: 1 T_hat: 150\n",
            "2022-12-04 02:04:02 - Uh4EsmHBcr0 - 426 of 3757 - PK: 0.54159 - WD: 0.96707 - T: 16 T_hat: 176\n",
            "2022-12-04 02:04:03 - 1muJRjN1v6Y - 427 of 3757 - PK: 0.62458 - WD: 1.0 - T: 1 T_hat: 187\n",
            "2022-12-04 02:04:04 - _yi1Z4PTIp0 - 428 of 3757 - PK: 0.57336 - WD: 0.90739 - T: 30 T_hat: 155\n",
            "2022-12-04 02:04:05 - 38mIIhptyg4 - 429 of 3757 - PK: 0.66736 - WD: 1.0 - T: 1 T_hat: 160\n",
            "2022-12-04 02:04:06 - 6Iccx3yqoII - 430 of 3757 - PK: 0.78503 - WD: 1.0 - T: 3 T_hat: 109\n",
            "2022-12-04 02:04:07 - plT99JRGXcQ - 431 of 3757 - PK: 0.78899 - WD: 1.0 - T: 1 T_hat: 73\n",
            "2022-12-04 02:04:08 - jvYke2y92S4 - 432 of 3757 - PK: 0.49533 - WD: 0.61215 - T: 18 T_hat: 30\n",
            "2022-12-04 02:04:09 - OjsQGNGApSs - 433 of 3757 - PK: 0.5766 - WD: 0.96386 - T: 16 T_hat: 141\n",
            "2022-12-04 02:04:10 - MsGyuTuGY8U - 434 of 3757 - PK: 0.99779 - WD: 1.0 - T: 1 T_hat: 140\n",
            "2022-12-04 02:04:11 - FAIGpjPpSWQ - 435 of 3757 - PK: 0.61605 - WD: 0.89154 - T: 12 T_hat: 72\n",
            "2022-12-04 02:04:12 - PHPTHHOJBBc - 436 of 3757 - PK: 0.66571 - WD: 1.0 - T: 2 T_hat: 72\n",
            "2022-12-04 02:04:13 - OrXtmMivYQ8 - 437 of 3757 - PK: 0.57234 - WD: 0.85374 - T: 21 T_hat: 110\n",
            "2022-12-04 02:04:14 - XROdqMLp_d4 - 438 of 3757 - PK: 0.98759 - WD: 1.0 - T: 3 T_hat: 146\n",
            "2022-12-04 02:04:16 - j-cbi6dhR7Q - 439 of 3757 - PK: 0.72314 - WD: 0.98483 - T: 9 T_hat: 140\n",
            "2022-12-04 02:04:17 - Uko6m4m7krA - 440 of 3757 - PK: 0.76755 - WD: 1.0 - T: 1 T_hat: 131\n",
            "2022-12-04 02:04:18 - XYzOsKleoek - 441 of 3757 - PK: 0.58148 - WD: 1.0 - T: 5 T_hat: 102\n",
            "2022-12-04 02:04:19 - 4JVhTdTiXiA - 442 of 3757 - PK: 0.71901 - WD: 0.92355 - T: 10 T_hat: 84\n",
            "2022-12-04 02:04:20 - lC6itYaKCng - 443 of 3757 - PK: 0.5 - WD: 0.92261 - T: 13 T_hat: 84\n",
            "2022-12-04 02:04:21 - pNu9tou-F3I - 444 of 3757 - PK: 0.61307 - WD: 0.87456 - T: 17 T_hat: 82\n",
            "2022-12-04 02:04:22 - xOWgD4kiuqA - 445 of 3757 - PK: 0.58837 - WD: 0.7907 - T: 22 T_hat: 66\n",
            "2022-12-04 02:04:23 - 8-2fSSz_ULI - 446 of 3757 - PK: 0.59896 - WD: 0.81771 - T: 15 T_hat: 57\n",
            "2022-12-04 02:04:24 - zPlGym9wSOc - 447 of 3757 - PK: 0.56332 - WD: 0.99782 - T: 7 T_hat: 79\n",
            "2022-12-04 02:04:25 - 85M5SFCCJmA - 448 of 3757 - PK: 0.54061 - WD: 1.0 - T: 9 T_hat: 144\n",
            "2022-12-04 02:04:26 - 5r7sKVuczhg - 449 of 3757 - PK: 0.62414 - WD: 0.97414 - T: 10 T_hat: 99\n",
            "2022-12-04 02:04:27 - jYN1XjLiLFw - 450 of 3757 - PK: 0.57912 - WD: 1.0 - T: 10 T_hat: 154\n",
            "2022-12-04 02:04:28 - UwEj2s3tFfU - 451 of 3757 - PK: 0.68157 - WD: 0.92484 - T: 20 T_hat: 155\n",
            "2022-12-04 02:04:29 - LuAfmbFk6DE - 452 of 3757 - PK: 0.58438 - WD: 0.72292 - T: 29 T_hat: 67\n",
            "2022-12-04 02:04:30 - 5dccNMyoTwE - 453 of 3757 - PK: 0.56106 - WD: 0.76238 - T: 16 T_hat: 50\n",
            "2022-12-04 02:04:31 - LfqzrOaxRUg - 454 of 3757 - PK: 0.56886 - WD: 0.70659 - T: 21 T_hat: 53\n",
            "2022-12-04 02:04:32 - Zh58PJI6FbI - 455 of 3757 - PK: 0.48361 - WD: 0.64208 - T: 27 T_hat: 50\n",
            "2022-12-04 02:04:33 - 0ym3PYht3dc - 456 of 3757 - PK: 0.44068 - WD: 0.58454 - T: 32 T_hat: 67\n",
            "2022-12-04 02:04:34 - SmedlrDB8ws - 457 of 3757 - PK: 0.46992 - WD: 0.58271 - T: 25 T_hat: 43\n",
            "2022-12-04 02:04:35 - -pczGqVEkig - 458 of 3757 - PK: 0.50102 - WD: 0.88776 - T: 13 T_hat: 86\n",
            "2022-12-04 02:04:36 - RKwb4EGUhPg - 459 of 3757 - PK: 0.53453 - WD: 0.72449 - T: 21 T_hat: 60\n",
            "2022-12-04 02:04:37 - jchGeFcvo78 - 460 of 3757 - PK: 0.54118 - WD: 0.59412 - T: 23 T_hat: 27\n",
            "2022-12-04 02:04:38 - lJISTpomoLA - 461 of 3757 - PK: 0.52283 - WD: 0.74715 - T: 23 T_hat: 81\n",
            "2022-12-04 02:04:39 - FF9TQoR6d6Q - 462 of 3757 - PK: 0.5191 - WD: 0.68539 - T: 22 T_hat: 68\n",
            "2022-12-04 02:04:40 - IFIKF0w8uiA - 463 of 3757 - PK: 0.61506 - WD: 0.74583 - T: 13 T_hat: 37\n",
            "2022-12-04 02:04:41 - WjaCrZGdzxI - 464 of 3757 - PK: 0.45946 - WD: 0.57432 - T: 32 T_hat: 66\n",
            "2022-12-04 02:04:42 - B83uJMHUitw - 465 of 3757 - PK: 0.43385 - WD: 0.58282 - T: 22 T_hat: 48\n",
            "2022-12-04 02:04:43 - l_tfzUQ_vKs - 466 of 3757 - PK: 0.4521 - WD: 0.68955 - T: 20 T_hat: 56\n",
            "2022-12-04 02:04:44 - 1aUxhbqPD9A - 467 of 3757 - PK: 0.4359 - WD: 0.55966 - T: 31 T_hat: 56\n",
            "2022-12-04 02:04:45 - -0mDwLSjp2c - 468 of 3757 - PK: 0.42775 - WD: 0.53468 - T: 33 T_hat: 55\n",
            "2022-12-04 02:04:46 - GiFDc_fEbFw - 469 of 3757 - PK: 0.53348 - WD: 0.73884 - T: 23 T_hat: 69\n",
            "2022-12-04 02:04:47 - cy3VV4DvPC8 - 470 of 3757 - PK: 0.55438 - WD: 0.79841 - T: 17 T_hat: 61\n",
            "2022-12-04 02:04:48 - dLpw58pFl88 - 471 of 3757 - PK: 0.49367 - WD: 0.78165 - T: 11 T_hat: 53\n",
            "2022-12-04 02:04:49 - uMRZxDyurLU - 472 of 3757 - PK: 0.64043 - WD: 0.88211 - T: 24 T_hat: 118\n",
            "2022-12-04 02:04:50 - t9eoaTAJ9UQ - 473 of 3757 - PK: 0.59051 - WD: 0.73814 - T: 31 T_hat: 88\n",
            "2022-12-04 02:04:51 - RO6DuI9xEjg - 474 of 3757 - PK: 0.71622 - WD: 0.75676 - T: 3 T_hat: 13\n",
            "2022-12-04 02:04:52 - 6WQi-zsXauI - 475 of 3757 - PK: 0.58446 - WD: 0.70608 - T: 22 T_hat: 45\n",
            "2022-12-04 02:04:53 - cN0GE6kOoYg - 476 of 3757 - PK: 0.56498 - WD: 0.85463 - T: 28 T_hat: 151\n",
            "2022-12-04 02:04:55 - tQ3voqB1rN0 - 477 of 3757 - PK: 0.59819 - WD: 0.72686 - T: 28 T_hat: 66\n",
            "2022-12-04 02:04:56 - m9OUZMukY1A - 478 of 3757 - PK: 0.41392 - WD: 0.6044 - T: 17 T_hat: 45\n",
            "2022-12-04 02:04:57 - oB6pyhDZESU - 479 of 3757 - PK: 0.53265 - WD: 0.68729 - T: 35 T_hat: 93\n",
            "2022-12-04 02:04:58 - 0HezK-soPl4 - 480 of 3757 - PK: 0.40816 - WD: 0.40816 - T: 10 T_hat: 9\n",
            "2022-12-04 02:04:59 - z6BP1kaYYwA - 481 of 3757 - PK: 0.54154 - WD: 0.72923 - T: 16 T_hat: 52\n",
            "2022-12-04 02:05:00 - Bc4F_LA6yJ8 - 482 of 3757 - PK: 0.51765 - WD: 0.75953 - T: 15 T_hat: 58\n",
            "2022-12-04 02:05:01 - PyJp-8yqKbY - 483 of 3757 - PK: 0.77647 - WD: 0.84706 - T: 3 T_hat: 16\n",
            "2022-12-04 02:05:02 - FyMIREdbBRc - 484 of 3757 - PK: 0.46429 - WD: 0.69457 - T: 31 T_hat: 95\n",
            "2022-12-04 02:05:03 - hLMbrXZOxCw - 485 of 3757 - PK: 0.51982 - WD: 0.7533 - T: 11 T_hat: 33\n",
            "2022-12-04 02:05:04 - ckuFH4FaH7g - 486 of 3757 - PK: 0.57312 - WD: 0.78656 - T: 12 T_hat: 41\n",
            "2022-12-04 02:05:05 - L3cLu0F2Bhs - 487 of 3757 - PK: 0.5364 - WD: 0.81751 - T: 27 T_hat: 113\n",
            "2022-12-04 02:05:06 - k96aEm7O3bw - 488 of 3757 - PK: 0.58824 - WD: 0.57143 - T: 3 T_hat: 7\n",
            "2022-12-04 02:05:07 - JpA8n4eEY3s - 489 of 3757 - PK: 0.4555 - WD: 0.60471 - T: 23 T_hat: 58\n",
            "2022-12-04 02:05:08 - -1mp-66xaNw - 490 of 3757 - PK: 0.52872 - WD: 0.6863 - T: 42 T_hat: 103\n",
            "2022-12-04 02:05:09 - 6LZr5_yykh4 - 491 of 3757 - PK: 0.41509 - WD: 0.56604 - T: 3 T_hat: 7\n",
            "2022-12-04 02:05:10 - wr8kFqGxuUg - 492 of 3757 - PK: 0.46733 - WD: 0.73123 - T: 19 T_hat: 79\n",
            "2022-12-04 02:05:11 - _Cw72DhslmY - 493 of 3757 - PK: 0.49302 - WD: 0.5814 - T: 19 T_hat: 32\n",
            "2022-12-04 02:05:12 - Y68mjzMBIVI - 494 of 3757 - PK: 0.60413 - WD: 0.69606 - T: 38 T_hat: 78\n",
            "2022-12-04 02:05:13 - tQ1uO27ar5c - 495 of 3757 - PK: 0.56757 - WD: 0.62838 - T: 30 T_hat: 45\n",
            "2022-12-04 02:05:14 - 8PQ5XUjBcy4 - 496 of 3757 - PK: 0.52282 - WD: 0.70124 - T: 14 T_hat: 37\n",
            "2022-12-04 02:05:15 - BE5dV2uAiXQ - 497 of 3757 - PK: 0.59172 - WD: 0.76036 - T: 19 T_hat: 56\n",
            "2022-12-04 02:05:16 - ytWYwxs-v9s - 498 of 3757 - PK: 0.50565 - WD: 0.6169 - T: 32 T_hat: 67\n",
            "2022-12-04 02:05:17 - _hjLUuH8gDs - 499 of 3757 - PK: 0.47006 - WD: 0.65569 - T: 22 T_hat: 50\n",
            "2022-12-04 02:05:18 - iHG2Fea_sgc - 500 of 3757 - PK: 0.59211 - WD: 0.86089 - T: 17 T_hat: 67\n",
            "2022-12-04 02:05:19 - fWJBnBdFB_0 - 501 of 3757 - PK: 0.45584 - WD: 0.54131 - T: 34 T_hat: 55\n",
            "2022-12-04 02:05:21 - YKZ5CiZnfPc - 502 of 3757 - PK: 0.48229 - WD: 0.58583 - T: 29 T_hat: 58\n",
            "2022-12-04 02:05:22 - M9twhTXD8vc - 503 of 3757 - PK: 0.57353 - WD: 0.64118 - T: 24 T_hat: 48\n",
            "2022-12-04 02:05:23 - OPzCw8cFZvY - 504 of 3757 - PK: 0.63478 - WD: 0.76812 - T: 22 T_hat: 56\n",
            "2022-12-04 02:05:24 - qyHT_yM80IQ - 505 of 3757 - PK: 0.54876 - WD: 0.76099 - T: 27 T_hat: 86\n",
            "2022-12-04 02:05:25 - 4FvwoeQ7G2o - 506 of 3757 - PK: 0.49731 - WD: 0.64516 - T: 27 T_hat: 62\n",
            "2022-12-04 02:05:26 - RKAg9cxAn-w - 507 of 3757 - PK: 0.45302 - WD: 0.56187 - T: 27 T_hat: 46\n",
            "2022-12-04 02:05:27 - yD7FrSrUsp4 - 508 of 3757 - PK: 0.45701 - WD: 0.50226 - T: 26 T_hat: 35\n",
            "2022-12-04 02:05:28 - WfQx9xVkFVs - 509 of 3757 - PK: 0.48986 - WD: 0.68986 - T: 21 T_hat: 61\n",
            "2022-12-04 02:05:29 - 7Be50CtP-as - 510 of 3757 - PK: 0.50318 - WD: 0.60828 - T: 27 T_hat: 46\n",
            "2022-12-04 02:05:30 - u3emNVS0gFI - 511 of 3757 - PK: 0.5 - WD: 0.6223 - T: 20 T_hat: 41\n",
            "2022-12-04 02:05:31 - gQ6wC1za43Y - 512 of 3757 - PK: 0.60544 - WD: 0.75057 - T: 22 T_hat: 66\n",
            "2022-12-04 02:05:32 - cq_27BlKBRo - 513 of 3757 - PK: 0.51479 - WD: 0.67751 - T: 23 T_hat: 58\n",
            "2022-12-04 02:05:33 - wKC6jU2uOsU - 514 of 3757 - PK: 0.53017 - WD: 0.74744 - T: 37 T_hat: 123\n",
            "2022-12-04 02:05:35 - KiKkjVJ98GA - 515 of 3757 - PK: 0.45685 - WD: 0.62025 - T: 26 T_hat: 71\n",
            "2022-12-04 02:05:36 - x4Ao13d50pw - 516 of 3757 - PK: 0.58108 - WD: 0.74667 - T: 3 T_hat: 13\n",
            "2022-12-04 02:05:37 - Qb_stMOTYeg - 517 of 3757 - PK: 0.51167 - WD: 0.67563 - T: 37 T_hat: 104\n",
            "2022-12-04 02:05:38 - JnJqWii27yc - 518 of 3757 - PK: 0.53941 - WD: 0.61576 - T: 40 T_hat: 62\n",
            "2022-12-04 02:05:39 - KCdZOqZeSJQ - 519 of 3757 - PK: 0.5 - WD: 0.63087 - T: 26 T_hat: 45\n",
            "2022-12-04 02:05:40 - 13gL_JX7Wn4 - 520 of 3757 - PK: 0.50804 - WD: 0.77885 - T: 15 T_hat: 56\n",
            "2022-12-04 02:05:41 - mzOgkwY5_VE - 521 of 3757 - PK: 0.50758 - WD: 0.73864 - T: 14 T_hat: 44\n",
            "2022-12-04 02:05:42 - ecjbodQoxbY - 522 of 3757 - PK: 0.39931 - WD: 0.52595 - T: 22 T_hat: 49\n",
            "2022-12-04 02:05:43 - YMb_1RJiSJo - 523 of 3757 - PK: 0.46768 - WD: 0.47727 - T: 37 T_hat: 44\n",
            "2022-12-04 02:05:44 - v2WGWfUxN0Q - 524 of 3757 - PK: 0.43116 - WD: 0.51087 - T: 26 T_hat: 40\n",
            "2022-12-04 02:05:45 - og3Xzn6vyYM - 525 of 3757 - PK: 0.51877 - WD: 0.77304 - T: 25 T_hat: 88\n",
            "2022-12-04 02:05:46 - awSb_cGJ_HI - 526 of 3757 - PK: 0.7 - WD: 0.9 - T: 3 T_hat: 12\n",
            "2022-12-04 02:05:47 - LnBQYoXmMVM - 527 of 3757 - PK: 0.4939 - WD: 0.60366 - T: 24 T_hat: 48\n",
            "2022-12-04 02:05:48 - enKZ8DW5SVg - 528 of 3757 - PK: 0.46771 - WD: 0.71037 - T: 25 T_hat: 79\n",
            "2022-12-04 02:05:50 - 7gfWQpZnULI - 529 of 3757 - PK: 0.49034 - WD: 0.75121 - T: 19 T_hat: 62\n",
            "2022-12-04 02:05:51 - QgVaEUIhGCk - 530 of 3757 - PK: 0.52198 - WD: 0.80822 - T: 15 T_hat: 55\n",
            "2022-12-04 02:05:52 - podntJbyufw - 531 of 3757 - PK: 0.74699 - WD: 0.87952 - T: 3 T_hat: 12\n",
            "2022-12-04 02:05:54 - PljY1DZ3KIE - 532 of 3757 - PK: 0.6118 - WD: 0.75155 - T: 20 T_hat: 58\n",
            "2022-12-04 02:05:55 - Qz6PYFWiUJI - 533 of 3757 - PK: 0.58696 - WD: 0.71841 - T: 15 T_hat: 40\n",
            "2022-12-04 02:05:56 - 7uFw9wNMPWs - 534 of 3757 - PK: 0.54072 - WD: 0.73616 - T: 14 T_hat: 46\n",
            "2022-12-04 02:05:57 - jxAQDNk6UY0 - 535 of 3757 - PK: 0.46241 - WD: 0.6203 - T: 20 T_hat: 36\n",
            "2022-12-04 02:05:58 - hyzi0WP8Nks - 536 of 3757 - PK: 0.56041 - WD: 0.83548 - T: 17 T_hat: 60\n",
            "2022-12-04 02:05:59 - 1UAy4bVOzxQ - 537 of 3757 - PK: 0.49741 - WD: 0.62435 - T: 27 T_hat: 58\n",
            "2022-12-04 02:06:00 - ux0RWenZijE - 538 of 3757 - PK: 0.45646 - WD: 0.69069 - T: 19 T_hat: 58\n",
            "2022-12-04 02:06:01 - RIdmgz-hw8I - 539 of 3757 - PK: 0.5817 - WD: 0.68301 - T: 19 T_hat: 39\n",
            "2022-12-04 02:06:02 - xUcUyVMsDaA - 540 of 3757 - PK: 0.49848 - WD: 0.62424 - T: 22 T_hat: 54\n",
            "2022-12-04 02:06:03 - htjudChb11E - 541 of 3757 - PK: 0.42489 - WD: 0.67382 - T: 12 T_hat: 35\n",
            "2022-12-04 02:06:05 - 4FxXieHwcps - 542 of 3757 - PK: 0.78947 - WD: 0.78947 - T: 3 T_hat: 10\n",
            "2022-12-04 02:06:06 - vWdhIwsiyo8 - 543 of 3757 - PK: 0.5323 - WD: 0.77247 - T: 36 T_hat: 118\n",
            "2022-12-04 02:06:07 - 3uT_ZwUpaMM - 544 of 3757 - PK: 0.62535 - WD: 0.80845 - T: 18 T_hat: 62\n",
            "2022-12-04 02:06:08 - bcI9uBqGaIg - 545 of 3757 - PK: 0.76389 - WD: 0.97222 - T: 3 T_hat: 17\n",
            "2022-12-04 02:06:09 - xK4jvH4JvKg - 546 of 3757 - PK: 0.56784 - WD: 0.80151 - T: 20 T_hat: 67\n",
            "2022-12-04 02:06:10 - XihsATATeNw - 547 of 3757 - PK: 0.57911 - WD: 0.71924 - T: 19 T_hat: 47\n",
            "2022-12-04 02:06:11 - REOsGveeAxg - 548 of 3757 - PK: 0.49074 - WD: 0.60648 - T: 15 T_hat: 33\n",
            "2022-12-04 02:06:12 - Gu3rGzEWamU - 549 of 3757 - PK: 0.51429 - WD: 0.64767 - T: 26 T_hat: 61\n",
            "2022-12-04 02:06:13 - gbqIMW13AUI - 550 of 3757 - PK: 0.46296 - WD: 0.48148 - T: 3 T_hat: 8\n",
            "2022-12-04 02:06:14 - _d0Zid_m-yg - 551 of 3757 - PK: 0.55251 - WD: 0.69863 - T: 19 T_hat: 35\n",
            "2022-12-04 02:06:16 - -3Lr7NrFNmw - 552 of 3757 - PK: 0.48878 - WD: 0.71571 - T: 20 T_hat: 63\n",
            "2022-12-04 02:06:17 - 7szBQItJ4ws - 553 of 3757 - PK: 0.50732 - WD: 0.83171 - T: 14 T_hat: 71\n",
            "2022-12-04 02:06:18 - A4kEQyXaCbQ - 554 of 3757 - PK: 0.56997 - WD: 0.79352 - T: 30 T_hat: 102\n",
            "2022-12-04 02:06:19 - Ult634Efp5M - 555 of 3757 - PK: 0.40203 - WD: 0.64865 - T: 15 T_hat: 48\n",
            "2022-12-04 02:06:20 - T8_vrwCwlAA - 556 of 3757 - PK: 0.53061 - WD: 0.69388 - T: 24 T_hat: 60\n",
            "2022-12-04 02:06:21 - fq-L5jfSoqI - 557 of 3757 - PK: 0.49858 - WD: 0.79487 - T: 27 T_hat: 117\n",
            "2022-12-04 02:06:22 - jryVtSAaQkI - 558 of 3757 - PK: 0.76562 - WD: 0.81538 - T: 3 T_hat: 10\n",
            "2022-12-04 02:06:23 - Wuk9gLIiGlI - 559 of 3757 - PK: 0.51394 - WD: 0.70916 - T: 14 T_hat: 43\n",
            "2022-12-04 02:06:24 - ccWgPklsgOk - 560 of 3757 - PK: 0.49854 - WD: 0.67638 - T: 22 T_hat: 55\n",
            "2022-12-04 02:06:25 - 54T7RNrb_Qg - 561 of 3757 - PK: 0.65517 - WD: 0.69492 - T: 3 T_hat: 7\n",
            "2022-12-04 02:06:27 - G4tYr_r-5IE - 562 of 3757 - PK: 0.47836 - WD: 0.65455 - T: 23 T_hat: 67\n",
            "2022-12-04 02:06:28 - uEwAXXEDLUQ - 563 of 3757 - PK: 0.47504 - WD: 0.66238 - T: 41 T_hat: 112\n",
            "2022-12-04 02:06:29 - gopo-pE4Y50 - 564 of 3757 - PK: 0.52322 - WD: 0.6935 - T: 35 T_hat: 106\n",
            "2022-12-04 02:06:30 - EybBnujOoCA - 565 of 3757 - PK: 0.5782 - WD: 0.66351 - T: 15 T_hat: 32\n",
            "2022-12-04 02:06:31 - biquWA4abF4 - 566 of 3757 - PK: 0.64151 - WD: 0.67925 - T: 3 T_hat: 9\n",
            "2022-12-04 02:06:32 - j3GsW6-Ww6I - 567 of 3757 - PK: 0.53036 - WD: 0.7938 - T: 26 T_hat: 120\n",
            "2022-12-04 02:06:33 - kRU6pxbsC1w - 568 of 3757 - PK: 0.8 - WD: 0.83333 - T: 3 T_hat: 7\n",
            "2022-12-04 02:06:35 - GmIgvnLcwds - 569 of 3757 - PK: 0.50549 - WD: 0.78082 - T: 15 T_hat: 59\n",
            "2022-12-04 02:06:36 - bx94QJY1MkQ - 570 of 3757 - PK: 0.46034 - WD: 0.78045 - T: 30 T_hat: 117\n",
            "2022-12-04 02:06:37 - srrk2JhxJpI - 571 of 3757 - PK: 0.61942 - WD: 0.7664 - T: 24 T_hat: 66\n",
            "2022-12-04 02:06:38 - 5Mqj5R111j4 - 572 of 3757 - PK: 0.63235 - WD: 0.82609 - T: 3 T_hat: 12\n",
            "2022-12-04 02:06:39 - GjQUJR4j_gI - 573 of 3757 - PK: 0.42667 - WD: 0.59467 - T: 27 T_hat: 56\n",
            "2022-12-04 02:06:40 - 9wyjSPP9iaw - 574 of 3757 - PK: 0.67925 - WD: 0.69811 - T: 3 T_hat: 10\n",
            "2022-12-04 02:06:41 - DJsfnbKtXes - 575 of 3757 - PK: 0.42133 - WD: 0.60267 - T: 24 T_hat: 56\n",
            "2022-12-04 02:06:42 - k0P_g7CTUB4 - 576 of 3757 - PK: 0.42601 - WD: 0.63229 - T: 23 T_hat: 73\n",
            "2022-12-04 02:06:45 - GsM4n1btifM - 577 of 3757 - PK: 0.55435 - WD: 0.80652 - T: 20 T_hat: 70\n",
            "2022-12-04 02:06:46 - xAiogA2S3dw - 578 of 3757 - PK: 0.50204 - WD: 0.66122 - T: 15 T_hat: 41\n",
            "2022-12-04 02:06:47 - dl7rqMo0RWU - 579 of 3757 - PK: 0.70455 - WD: 0.66667 - T: 3 T_hat: 8\n",
            "2022-12-04 02:06:48 - 7S6gAO_GC6g - 580 of 3757 - PK: 0.5144 - WD: 0.72016 - T: 23 T_hat: 72\n",
            "2022-12-04 02:06:49 - DpCFaWwoV50 - 581 of 3757 - PK: 0.43968 - WD: 0.63271 - T: 23 T_hat: 57\n",
            "2022-12-04 02:06:50 - VSuQnlDmSFE - 582 of 3757 - PK: 0.54231 - WD: 0.71538 - T: 13 T_hat: 33\n",
            "2022-12-04 02:06:51 - 7uFxinJmD9g - 583 of 3757 - PK: 0.74419 - WD: 0.96512 - T: 3 T_hat: 16\n",
            "2022-12-04 02:06:52 - GN7KH8AimuY - 584 of 3757 - PK: 0.50355 - WD: 0.80851 - T: 10 T_hat: 53\n",
            "2022-12-04 02:06:53 - nU7zuii1gYA - 585 of 3757 - PK: 0.56657 - WD: 0.76554 - T: 17 T_hat: 53\n",
            "2022-12-04 02:06:55 - RoCXSB3PfDY - 586 of 3757 - PK: 0.54812 - WD: 0.75 - T: 13 T_hat: 38\n",
            "2022-12-04 02:06:56 - E8GPqoDuMlk - 587 of 3757 - PK: 0.54341 - WD: 0.86826 - T: 18 T_hat: 115\n",
            "2022-12-04 02:06:57 - VnTXsSXr6bQ - 588 of 3757 - PK: 0.45652 - WD: 0.58696 - T: 3 T_hat: 7\n",
            "2022-12-04 02:06:58 - UQb5pVVZZks - 589 of 3757 - PK: 0.564 - WD: 0.828 - T: 12 T_hat: 48\n",
            "2022-12-04 02:06:59 - YjKVRK28Jd0 - 590 of 3757 - PK: 0.53602 - WD: 0.78602 - T: 18 T_hat: 77\n",
            "2022-12-04 02:07:00 - 5xD_Xn7qkiM - 591 of 3757 - PK: 0.62567 - WD: 0.86898 - T: 24 T_hat: 124\n",
            "2022-12-04 02:07:02 - PYjdxsxQz90 - 592 of 3757 - PK: 0.48547 - WD: 0.70145 - T: 14 T_hat: 55\n",
            "2022-12-04 02:07:03 - k8pNLMwEi8A - 593 of 3757 - PK: 0.50211 - WD: 0.72152 - T: 14 T_hat: 39\n",
            "2022-12-04 02:07:04 - PBJRHes6peA - 594 of 3757 - PK: 0.44898 - WD: 0.44 - T: 3 T_hat: 8\n",
            "2022-12-04 02:07:05 - p3FjlxaRADs - 595 of 3757 - PK: 0.52051 - WD: 0.71795 - T: 22 T_hat: 67\n",
            "2022-12-04 02:07:06 - S37JOquZ8vA - 596 of 3757 - PK: 0.70667 - WD: 0.82895 - T: 4 T_hat: 14\n",
            "2022-12-04 02:07:07 - 1M1lGOYfW7s - 597 of 3757 - PK: 0.57963 - WD: 0.76501 - T: 18 T_hat: 57\n",
            "2022-12-04 02:07:09 - f2ESZDzZGak - 598 of 3757 - PK: 0.50957 - WD: 0.76914 - T: 28 T_hat: 138\n",
            "2022-12-04 02:07:10 - dyQUixQZiNo - 599 of 3757 - PK: 0.58824 - WD: 0.74613 - T: 14 T_hat: 49\n",
            "2022-12-04 02:07:11 - GmDMBMzCiZc - 600 of 3757 - PK: 0.47181 - WD: 0.75371 - T: 19 T_hat: 56\n",
            "2022-12-04 02:07:12 - iY9JN9-34RQ - 601 of 3757 - PK: 0.60067 - WD: 0.73154 - T: 19 T_hat: 52\n",
            "2022-12-04 02:07:13 - Edi06hRiekQ - 602 of 3757 - PK: 0.57431 - WD: 0.84887 - T: 16 T_hat: 72\n",
            "2022-12-04 02:07:14 - u7HWRZWgETs - 603 of 3757 - PK: 0.62411 - WD: 0.86879 - T: 18 T_hat: 92\n",
            "2022-12-04 02:07:16 - 8JzFHERVd58 - 604 of 3757 - PK: 0.59765 - WD: 0.92 - T: 12 T_hat: 68\n",
            "2022-12-04 02:07:17 - 7fBJ5MEvoBU - 605 of 3757 - PK: 0.55263 - WD: 0.73947 - T: 21 T_hat: 63\n",
            "2022-12-04 02:07:18 - 6Ot9iMCH0lQ - 606 of 3757 - PK: 0.5125 - WD: 0.6875 - T: 15 T_hat: 38\n",
            "2022-12-04 02:07:19 - UFoZ5Qkhy30 - 607 of 3757 - PK: 0.5 - WD: 0.71733 - T: 16 T_hat: 45\n",
            "2022-12-04 02:07:20 - LKwmYKy3TT8 - 608 of 3757 - PK: 0.57143 - WD: 0.55556 - T: 2 T_hat: 6\n",
            "2022-12-04 02:07:21 - CfpuGXw4Ic8 - 609 of 3757 - PK: 0.51846 - WD: 0.66769 - T: 35 T_hat: 103\n",
            "2022-12-04 02:07:23 - A0Pfcd67MOc - 610 of 3757 - PK: 0.4973 - WD: 0.59279 - T: 58 T_hat: 87\n",
            "2022-12-04 02:07:24 - mnF_Gy84jy4 - 611 of 3757 - PK: 0.73554 - WD: 0.95041 - T: 3 T_hat: 23\n",
            "2022-12-04 02:07:25 - 8bmZMRGtKjc - 612 of 3757 - PK: 0.62617 - WD: 0.80997 - T: 13 T_hat: 51\n",
            "2022-12-04 02:07:26 - Tgp2GiFbhDk - 613 of 3757 - PK: 0.56481 - WD: 0.79012 - T: 13 T_hat: 46\n",
            "2022-12-04 02:07:27 - D9gyYYhj708 - 614 of 3757 - PK: 0.44802 - WD: 0.67901 - T: 18 T_hat: 59\n",
            "2022-12-04 02:07:28 - 07Ssh_xhuKc - 615 of 3757 - PK: 0.48889 - WD: 0.57778 - T: 3 T_hat: 9\n",
            "2022-12-04 02:07:29 - PwrmSZxzwQI - 616 of 3757 - PK: 0.59077 - WD: 0.82154 - T: 13 T_hat: 49\n",
            "2022-12-04 02:07:31 - QbqKJwLM_Jg - 617 of 3757 - PK: 0.50523 - WD: 0.66551 - T: 18 T_hat: 49\n",
            "2022-12-04 02:07:32 - 7ELlvyu0lbk - 618 of 3757 - PK: 0.44554 - WD: 0.66667 - T: 17 T_hat: 54\n",
            "2022-12-04 02:07:33 - wlNp1Vi08Uw - 619 of 3757 - PK: 0.58182 - WD: 0.65455 - T: 3 T_hat: 8\n",
            "2022-12-04 02:07:34 - PS5GsjZwAFo - 620 of 3757 - PK: 0.58076 - WD: 0.73883 - T: 16 T_hat: 52\n",
            "2022-12-04 02:07:35 - JO4g6E_EUtM - 621 of 3757 - PK: 0.61202 - WD: 0.93625 - T: 14 T_hat: 93\n",
            "2022-12-04 02:07:36 - gtnRZbPnelg - 622 of 3757 - PK: 0.46964 - WD: 0.63968 - T: 16 T_hat: 40\n",
            "2022-12-04 02:07:38 - BmAjyuqTLkg - 623 of 3757 - PK: 0.56318 - WD: 0.74368 - T: 14 T_hat: 46\n"
          ]
        }
      ],
      "source": [
        "from transformers.models.auto.modeling_auto import MODEL_MAPPING_NAMES\n",
        "#@title Prepare embeddings and calculate Y_hat\n",
        "\n",
        "# Prepare Variables\n",
        "done_embeddings = []\n",
        "done_metrics = []\n",
        "sentence_embeddings_list = []\n",
        "Y_hat_list = []\n",
        "T_hat_list = []\n",
        "sims_list = []\n",
        "\n",
        "# define Pre_trainde_model_fullname\n",
        "pre_trained_model_fullname = str(pre_trained_model + '-' + dim_redux_method)# + \"-WS\" + similarity_window + \"-Z\" + str(Z) + \"-\" + z_partition_dataset)\n",
        "\n",
        "# Define Embeddings path depending on Dataset\n",
        "embeddings_path = os.path.join(dataset_path,'embeddings/', str(pre_trained_model_fullname + '/'))\n",
        "if dataset_name == \"YouTube\":\n",
        "  filename_folder = filename.split(\".\")[-2]\n",
        "  embeddings_path = os.path.join(dataset_path,'embeddings/', str(filename_folder), str(pre_trained_model_fullname + '/'))\n",
        "\n",
        "if baseline == \"NO\":\n",
        "  pre_trained_model_fullname_metrics_result = str(pre_trained_model + '-' + str(dim_redux_method) + \"-WS\" + str(similarity_window) + \"-Z\" + str(Z) + \"-\" + z_partition_dataset)\n",
        "else:\n",
        "  pre_trained_model_fullname_metrics_result = 'baseline-' + str(baseline) + \"-WS\" + str(similarity_window) + \"-Z\" + str(Z) + \"-\" + str(z_partition_dataset)\n",
        "\n",
        "# Define metrics_results path depending on Dataset\n",
        "metrics_results_path = os.path.join(dataset_path,'metrics_results/', str(pre_trained_model_fullname_metrics_result + '/'))\n",
        "if dataset_name == \"YouTube\":\n",
        "  filename_folder = filename.split(\".\")[-2]\n",
        "  metrics_results_path = os.path.join(dataset_path,'metrics_results/', str(filename_folder + '/'), str(pre_trained_model_fullname_metrics_result + '/'))\n",
        "metric_results_filename_path = os.path.join(metrics_results_path, str(\"results_\" + pre_trained_model_fullname + '.csv'))\n",
        "Y_hat_list_filename_path = os.path.join(metrics_results_path, str(\"Y_hat_list_\" + pre_trained_model_fullname + '.npy'))\n",
        "T_hat_list_filename_path = os.path.join(metrics_results_path, str(\"T_hat_list_\" + pre_trained_model_fullname + '.npy'))\n",
        "sims_list_filename_path = os.path.join(metrics_results_path, str(\"sims_list_\" + pre_trained_model_fullname + '.npy'))\n",
        "\n",
        "# Check if embeddings folder exists if not create it\n",
        "if not os.path.exists(metrics_results_path):\n",
        "   os.makedirs(metrics_results_path)\n",
        "   print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "         \" - \" + str(pre_trained_model_fullname_metrics_result) + \n",
        "         \" - metrics_results_path folder not found. New folder created\")\n",
        "\n",
        "# List all embeddings in folder embeddings_path and done metrics\n",
        "try:\n",
        "  print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                \" - Reading embeddings in path: \" + str(embeddings_path))\n",
        "  \n",
        "  done_embeddings = get_done_embeddings(embeddings_path)\n",
        "\n",
        "  print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                \" - Total embeddings: \" + str(len(done_embeddings)))\n",
        "  \n",
        "  print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                \" - Reading metrics in path: \" + str(metric_results_filename_path))\n",
        "  \n",
        "  done_metrics, PK_metrics, WD_metrics, Y_hat_list, T_hat_list, sims_list = get_done_metrics(metric_results_filename_path, Y_hat_list_filename_path, T_hat_list_filename_path, sims_list_filename_path)\n",
        "  \n",
        "  print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                \" - Total metrics: \" + str(len(done_metrics)))\n",
        "  \n",
        "  print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                \" - Total Y_hat_list: \" + str(len(Y_hat_list)))\n",
        "  \n",
        "  print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                \" - Total T_hat_list: \" + str(len(T_hat_list)))\n",
        "  \n",
        "  print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                \" - Total sims_list: \" + str(len(sims_list)))  \n",
        "except Exception as error:\n",
        "  print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "        \" - Error reading embeddings path: \" + str(metric_results_filename_path) + \n",
        "        \"\\n\" +\n",
        "        \" - Error: \" + str(error))\n",
        "\n",
        "if len(done_metrics) != len(Y_hat_list):\n",
        "  print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "      \" - Error Y_hat_list size\")\n",
        "  raise SystemExit\n",
        "\n",
        "# Initiate internal variables\n",
        "S_list_cropped = []\n",
        "T_list_cropped = []\n",
        "Y_list_cropped = []\n",
        "transcripts_list_cropped = []\n",
        "\n",
        "for done_embedding_idx, done_embedding in enumerate(done_embeddings):\n",
        "  if done_embedding not in transcripts_list:\n",
        "    print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "          \" - \" + str(done_embedding) + \n",
        "          \" - Skipping File. Not a transcript: \")\n",
        "    continue\n",
        "\n",
        "  S = []\n",
        "  T = []\n",
        "  Y = []\n",
        "  transcript_name_cropped = \"\"\n",
        "  sims = []\n",
        "  T_hat = []\n",
        "  R = None\n",
        "  csv_data = []\n",
        "\n",
        "  # Get Sentences, topics, outputs from list of created embedding (Embeddings in folder)\n",
        "  S, T, Y, transcript_name_cropped = get_meeting_sentences(done_embedding, S_list, T_list, Y_list, transcripts_list)\n",
        "  S_list_cropped.append(S)\n",
        "  T_list_cropped.append(T)\n",
        "  Y_list_cropped.append(Y)\n",
        "  transcripts_list_cropped.append(transcript_name_cropped)\n",
        "\n",
        "  if done_embedding not in done_metrics:\n",
        "\n",
        "    if baseline == \"NO\":\n",
        "      # Load tensors\n",
        "      if model_name == \"SBERT\":\n",
        "\n",
        "        # Load tensor files\n",
        "        try:\n",
        "          tensor_filename = embeddings_path + str(done_embedding) + '.pt'\n",
        "          R = torch.load(tensor_filename)\n",
        "\n",
        "          # Check if tensor size ok\n",
        "          if len(S) != len(R):\n",
        "          # if len(S) != R.size()[0]:\n",
        "            print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                  \" - \" + str(done_embedding) + \n",
        "                  \" - Error on Tensor size: \" + str(R.size()[0]) + \n",
        "                  \" - Sentence Size: \" + str(len(S)))\n",
        "            raise SystemExit\n",
        "        except Exception as error:\n",
        "          print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                \" - \" + str(done_embedding) + \n",
        "                \" - Error on Loading tensor file: \" + str(tensor_filename) +\n",
        "                \"\\n\" +\n",
        "                \" - Error : \" + str(error))\n",
        "          break\n",
        "\n",
        "      elif model_name == \"Universal Sentence Encoder\":\n",
        "        # Load tensor files\n",
        "        try:\n",
        "          tensor_filename = embeddings_path + str(done_embedding) + '.npy'\n",
        "          R = np.load(tensor_filename,allow_pickle=True).tolist()\n",
        "          # Check if tensor size ok\n",
        "          if len(S) != len(R):\n",
        "            print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                  \" - \" + str(done_embedding) + \n",
        "                  \" - Error on Tensor size: \" + str(len(R)) + \n",
        "                  \" - Sentence Size: \" + str(len(S)))\n",
        "            raise SystemExit\n",
        "        except Exception as error:\n",
        "          print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "                \" - \" + str(done_embedding) + \n",
        "                \" - Error on Loading tensor file: \" + str(tensor_filename) +\n",
        "                \"\\n\" +\n",
        "                \" - Error : \" + str(error))\n",
        "          break\n",
        "\n",
        "      # Calculate Similarity Vectors\n",
        "      try:\n",
        "        if similarity_window != \"1\":\n",
        "          if similarity_window != \"Average\":\n",
        "            similarity_window = int(similarity_window)\n",
        "            for R_idx, r_i in enumerate(R):\n",
        "              sim_before = []\n",
        "              sim_after = []\n",
        "              if R_idx == 0:\n",
        "                sim_i = 1\n",
        "              elif R_idx + 1 == len(R):\n",
        "                sim_i = 0\n",
        "              else:\n",
        "                if R_idx - similarity_window < 0:\n",
        "                  similarity_range = range(0,R_idx)\n",
        "                else:\n",
        "                  similarity_range = range(R_idx - similarity_window,R_idx)\n",
        "                sim_after  = cos_sim(R[R_idx],R[R_idx + 1])\n",
        "                for sim_indx in similarity_range:\n",
        "                  # print(\"index: \" + str(R_idx) + \" VS \" + str(sim_indx))\n",
        "                  sim_before.append(cos_sim(R[sim_indx], R[R_idx]))\n",
        "                # print(sim_before)\n",
        "                # print(similarity_range)\n",
        "                sim_i = np.mean(sim_before) + sim_after\n",
        "                # print(sim_i)\n",
        "              sims.append(sim_i)\n",
        "            sims_list.append(sims)\n",
        "          else:\n",
        "            similarity_window = 1\n",
        "        else:\n",
        "          r_i_1 = 0\n",
        "          for R_idx, r_i in enumerate(R):\n",
        "            if R_idx == 0:\n",
        "              # r_i_1 = np.ones_like(r_i)\n",
        "              sim_i = 1\n",
        "            else:\n",
        "              r_i_1 = R[R_idx - 1]\n",
        "              sim_i = cos_sim(r_i_1, r_i)\n",
        "            sims.append(sim_i)\n",
        "          sims_list.append(sims)\n",
        "      except Exception as error:\n",
        "        print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "              \" - \" + str(done_embedding) + \n",
        "              \" - Error calculating sims\" +\n",
        "              \"\\n\" +\n",
        "              \" - Error: \" + str(error))\n",
        "        break\n",
        "\n",
        "      # Calculate Y_hat, T_hat\n",
        "      try:\n",
        "        sim_treshold = 0\n",
        "        Y_hat = []\n",
        "        T_hat = []\n",
        "        miu = np.mean(sims)\n",
        "        sigma = np.std(sims)\n",
        "        for sim_idx, sim_i in enumerate(sims):\n",
        "          if sim_idx == 0:\n",
        "            t_start = sim_idx\n",
        "            Y_hat.append(1)\n",
        "          else:\n",
        "            sim_treshold = miu - (Z * sigma)\n",
        "            if sim_i < sim_treshold:\n",
        "              t_end = sim_idx\n",
        "              T_hat.append((t_start,t_end))\n",
        "              t_start = sim_idx + 1\n",
        "              Y_hat.append(1)\n",
        "            else:\n",
        "              Y_hat.append(0)\n",
        "        Y_hat_list.append(Y_hat)\n",
        "        T_hat_list.append(T_hat)\n",
        "      except Exception as error:\n",
        "        print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "              \" - \" + str(done_embedding) + \n",
        "              \" - Error Calculating Y_Hat, T_hat\" +\n",
        "              \"\\n\" +\n",
        "              \" - Error: \" + str(error))\n",
        "        break\n",
        "    \n",
        "    elif baseline == \"even\":\n",
        "      sims_list.append(sims)\n",
        "      Y_hat = even_baseline(Y)\n",
        "      if len(Y_hat) != len(Y):\n",
        "        print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "        \" - Error calculating even baseline. Y_hat_list size vs Y_list size\")\n",
        "        raise SystemExit\n",
        "      Y_hat_list.append(Y_hat)\n",
        "      for y_hat_idx, y_hat_i in enumerate(Y_hat):\n",
        "        if y_hat_idx == 0:\n",
        "          t_start = y_hat_idx\n",
        "        else:\n",
        "          if y_hat_i == 1:\n",
        "            t_end = y_hat_idx\n",
        "            T_hat.append((t_start,t_end))\n",
        "            t_start = y_hat_idx + 1\n",
        "      T_hat_list.append(T_hat)\n",
        "\n",
        "    elif baseline == \"random\":\n",
        "      sims_list.append(sims)\n",
        "      Y_hat = rand_baseline(Y)\n",
        "      if len(Y_hat) != len(Y):\n",
        "        print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "        \" - Error calculating random baseline. Y_hat_list size vs Y_list size\")\n",
        "        raise SystemExit\n",
        "      Y_hat_list.append(Y_hat)\n",
        "      for y_hat_idx, y_hat_i in enumerate(Y_hat):\n",
        "        if y_hat_idx == 0:\n",
        "          t_start = y_hat_idx\n",
        "        else:\n",
        "          if y_hat_i == 1:\n",
        "            t_end = y_hat_idx\n",
        "            T_hat.append((t_start,t_end))\n",
        "            t_start = y_hat_idx + 1\n",
        "      T_hat_list.append(T_hat)\n",
        "    \n",
        "    elif baseline == \"none\":\n",
        "      sims_list.append(sims)\n",
        "      Y_hat = none_baseline(Y)\n",
        "      if len(Y_hat) != len(Y):\n",
        "        print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "        \" - Error calculating none baseline. Y_hat_list size vs Y_list size\")\n",
        "        raise SystemExit\n",
        "      Y_hat_list.append(Y_hat)\n",
        "      for y_hat_idx, y_hat_i in enumerate(Y_hat):\n",
        "        if y_hat_idx == 0:\n",
        "          t_start = y_hat_idx\n",
        "        else:\n",
        "          if y_hat_i == 1:\n",
        "            t_end = y_hat_idx\n",
        "            T_hat.append((t_start,t_end))\n",
        "            t_start = y_hat_idx + 1\n",
        "      T_hat_list.append(T_hat)\n",
        "    \n",
        "    # Calculate Pk per video or meeting\n",
        "    try:\n",
        "      #legacy metric\n",
        "      # pk_metric_meeting = evaluate_pk(Y_hat, Y, int(average_sentences(Y)/2))\n",
        "      \n",
        "      #nltk PK metric, when k is not filled in, it auto calculates half of the average labeled segments\n",
        "      pk_metric_meeting = pk(''.join(str(i) for i in Y), ''.join(str(i) for i in Y_hat))\n",
        "    except Exception as error:\n",
        "      print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "            \" - \" + str(done_embedding) + \n",
        "            \" - Error Calculating PK\" +\n",
        "            \"\\n\" +\n",
        "            \" - Error: \" + str(error))\n",
        "      raise SystemExit\n",
        "    \n",
        "    # Calculate Wd per video or meeting\n",
        "    try:\n",
        "      #legacy metric\n",
        "      # wd_metric_meeting = evaluate_wd(Y_hat, Y, int(average_sentences(Y)/2))\n",
        "\n",
        "      #nltk wd metric, when k is not filled in, it auto calculates half of the average labeled segments\n",
        "      wd_metric_meeting = windowdiff(''.join(str(i) for i in Y), ''.join(str(i) for i in Y_hat), int(average_sentences(Y)/2))\n",
        "    except Exception as error:\n",
        "      print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "            \" - \" + str(done_embedding) + \n",
        "            \" - Error Calculating Wd\" +\n",
        "            \"\\n\" +\n",
        "            \" - Error: \" + str(error))\n",
        "      raise SystemExit\n",
        "    \n",
        "    if print_debug == \"Yes\":\n",
        "      print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "            \" - \" + str(done_embedding) + \n",
        "            \" - \" + str(done_embedding_idx + 1) + \" of \" + str(len(done_embeddings)) +\n",
        "            \" - PK: \" + str(round(pk_metric_meeting,5)) +\n",
        "            \" - WD: \" + str(round(wd_metric_meeting,5)) +\n",
        "            \" - T: \" + str(len(T)) +\n",
        "            \" T_hat: \" + str(np.sum(Y_hat)))\n",
        "    \n",
        "    # Save to results_*.csv File\n",
        "    try:\n",
        "      csv_data = [datetime.today().strftime('%Y-%m-%d %H:%M:%S'), done_embedding, pk_metric_meeting, wd_metric_meeting]\n",
        "      with open(metric_results_filename_path, 'a+', encoding='UTF8', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        # write multiple rows\n",
        "        writer.writerow(map(lambda x: x, csv_data))\n",
        "    except Exception as error:\n",
        "      print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "            \" - \" + str(done_embedding) + \n",
        "            \" - Error writing to file: \" + str(metric_results_filename_path) +\n",
        "            \"\\n\" +\n",
        "            \" - Error: \" + str(error))\n",
        "    \n",
        "    # Save Y_hat_list and T_hat_list, sims_list to file\n",
        "    try:\n",
        "      np.save(Y_hat_list_filename_path, np.asarray(Y_hat_list, dtype=object))\n",
        "    except Exception as error:\n",
        "      print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "            \" - \" + str(done_embedding) + \n",
        "            \" - Error writing to file: \" + str(Y_hat_list_filename_path) +\n",
        "            \"\\n\" +\n",
        "            \" - Error: \" + str(error))\n",
        "    \n",
        "    try:\n",
        "      np.save(T_hat_list_filename_path, np.asarray(T_hat_list, dtype=object))\n",
        "    except Exception as error:\n",
        "      print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "            \" - \" + str(done_embedding) + \n",
        "            \" - Error writing to file: \" + str(T_hat_list_filename_path) +\n",
        "            \"\\n\" +\n",
        "            \" - Error: \" + str(error))\n",
        "    \n",
        "    try:\n",
        "      np.save(sims_list_filename_path, np.asarray(sims_list, dtype=object))\n",
        "    except Exception as error:\n",
        "      print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "            \" - \" + str(done_embedding) + \n",
        "            \" - Error writing to file: \" + str(sims_list_filename_path) +\n",
        "            \"\\n\" +\n",
        "            \" - Error: \" + str(error))\n",
        "    \n",
        "    R = None\n",
        "\n",
        "    done_metrics.append(done_embedding)\n",
        "\n",
        "  else:\n",
        "    done_metrics_idx = done_metrics.index(done_embedding)\n",
        "    if print_debug == \"Yes\":\n",
        "      print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "            \" - \" + str(done_embedding) + \n",
        "            \" - Skipping tensor load. Reading from: \" + str(metric_results_filename_path) +\n",
        "            #\" - Skipping tensor load. Reading from: \" + str(metric_results_filename_path.split(\"/\")[-2]) + \"/\" + str(metric_results_filename_path.split(\"/\")[-1]) +\n",
        "            \" - \" + str(done_embedding_idx + 1) + \" of \" + str(len(done_embeddings)) +\n",
        "            \" - PK: \" + str(round(float(PK_metrics[done_metrics_idx]),5)) +\n",
        "            \" - WD: \" + str(round(float(WD_metrics[done_metrics_idx]),5)) +\n",
        "            \" - T: \" + str(len(T)) +\n",
        "            \" T_hat: \" + str(len(T_hat_list[done_metrics_idx])))\n",
        "\n",
        "    continue\n",
        "\n",
        "if metric_calculation == \"append\" or metric_calculation == \"smooth\":\n",
        "  # Calculate Y_Total and Y_hat_total\n",
        "  try:\n",
        "    Y_total = []\n",
        "    Y_hat_total = []\n",
        "    for Y_list_cropped_idx, Y in enumerate(Y_list_cropped):\n",
        "      if len(Y) != len(Y_hat_list[Y_list_cropped_idx]):\n",
        "        print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "          \" - \" + str(done_embedding) + \n",
        "          \" - Error Calculating Y_hat, Y sizes are different\" +\n",
        "          \"\\n\")\n",
        "        raise SystemExit\n",
        "      for y_idx, y in enumerate(Y):\n",
        "        Y_total.append(y)\n",
        "        Y_hat_total.append(Y_hat_list[Y_list_cropped_idx][y_idx])\n",
        "  except Exception as error:\n",
        "    print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "          \" - \" + str(done_embedding) + \n",
        "          \" - Error Calculating Y_total, Y_hat_total\" +\n",
        "          \"\\n\" +\n",
        "          \" - Error: \" + str(error))\n",
        "  \n",
        "  # Remove adjacent topic changes\n",
        "  if metric_calculation == \"smooth\":\n",
        "    Y_hat_total = clean_adj_topic(Y_hat_total)\n",
        "  \n",
        "  # Evaluate Pk Total\n",
        "  try:\n",
        "    pk_metric = 0\n",
        "    pk_metric = evaluate_pk(Y_hat_total, Y_total, int(average_sentences(Y_total)/2))\n",
        "  except Exception as error:\n",
        "    print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "          \" - \" + str(done_embedding) + \n",
        "          \" - Error Calculating PK\" +\n",
        "          \"\\n\" +\n",
        "          \" - Error: \" + str(error))\n",
        "    \n",
        "  # Evaluate Wd Total\n",
        "  try:\n",
        "    wd=metric = 0\n",
        "    wd_metric = evaluate_wd(Y_hat_total, Y_total, int(average_sentences(Y_total)/2))\n",
        "  except Exception as error:\n",
        "    print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "          \" - \" + str(done_embedding) + \n",
        "          \" - Error Calculating Wd\" +\n",
        "          \"\\n\" +\n",
        "          \" - Error: \" + str(error))    \n",
        "\n",
        "elif metric_calculation == \"average\":\n",
        "  Y_total = []\n",
        "  Y_hat_total = []\n",
        "  PK_metrics_cropped = []\n",
        "  WD_metrics_cropped = []\n",
        "  for transcript_idx, transcript in enumerate(transcripts_list_cropped):\n",
        "    metrics_cropeed_idx = done_metrics.index(transcript)\n",
        "    PK_metrics_cropped.append(PK_metrics[metrics_cropeed_idx])\n",
        "    WD_metrics_cropped.append(WD_metrics[metrics_cropeed_idx])\n",
        "  pk_metric = np.mean(PK_metrics_cropped)\n",
        "  wd_metric = np.mean(WD_metrics_cropped)\n",
        "\n",
        "# Evaluate total topic count\n",
        "topic_quantity_difference = []\n",
        "for transcript_cropped_idx, transcript_cropped in enumerate(transcripts_list_cropped):\n",
        "    transcript_idx = transcripts_list.index(transcript_cropped)\n",
        "    done_metrics_idx = done_metrics.index(transcript_cropped)\n",
        "    topic_quantity = len(T_list[transcript_idx])\n",
        "    topic_quantity_hat = len(T_hat_list[done_metrics_idx])\n",
        "    topic_quantity_difference.append(topic_quantity_hat-topic_quantity)\n",
        "\n",
        "# Calculate MAE\n",
        "if len(Y_list_cropped) != len(Y_hat_list):\n",
        "  print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "    \" - Error Y_hat_list size vs Y_list size\" + \n",
        "    \" - Y_hat embedding: \" +  transcript_cropped + \n",
        "    \" - Y_hat embedding: \" +  done_embeddings[done_metrics_idx])\n",
        "  raise SystemExit\n",
        "mae = mae_std(Y_list_cropped, Y_hat_list)\n",
        "\n",
        "\n",
        "\n",
        "# Print Results\n",
        "# try:\n",
        "print(\"\\n\")\n",
        "print(\"Size of sims_list:                 \" + str(len(sims_list)))\n",
        "print(\"Size of S_list_cropped:            \" + str(len(S_list_cropped)))\n",
        "print(\"Numb of transcripts S_list:        \" + str(len(S_list)))\n",
        "print(\"Size of T_list_cropped:            \" + str(len(T_list_cropped)))\n",
        "print(\"Numb of Topics T_list:             \" + str(len(T_list)))\n",
        "print(\"Size of Y_list_cropped:            \" + str(len(Y_list_cropped)))\n",
        "print(\"Numb of Outputs Y_list:            \" + str(len(Y_list)))\n",
        "print(\"Size of transcripts_list_cropped:  \" + str(len(transcripts_list_cropped)))\n",
        "print(\"Size of T_hat_list:                \" + str(len(T_hat_list)))\n",
        "print(\"Size of Y_hat_list:                \" + str(len(Y_hat_list)))\n",
        "print(\"Size of Y_total:                   \" + str(len(Y_total)))\n",
        "print(\"Size of Y_hat_total:               \" + str(len(Y_hat_total)))\n",
        "print(\"\\n\")\n",
        "\n",
        "index_test_cropped = 3\n",
        "index_test = transcripts_list.index(transcripts_list_cropped[index_test_cropped])\n",
        "print(\"Transcripts name:                  \" + str(transcripts_list[index_test]))\n",
        "print(\"Transcripts_cropped name:          \" + str(transcripts_list_cropped[index_test_cropped]))\n",
        "print(\"Numb of S_list in Test             \" + str(len(S_list[index_test])))\n",
        "print(\"Numb of S_list_cropped in Test     \" + str(len(S_list_cropped[index_test_cropped])))\n",
        "print(\"Numb of T_list in Test             \" + str(len(T_list[index_test])))\n",
        "print(\"Numb of T_list_cropped in Test     \" + str(len(T_list_cropped[index_test_cropped])))\n",
        "print(\"Numb of Y_list in Test             \" + str(len(Y_list[index_test])))\n",
        "print(\"Numb of Y_list_cropped in Test     \" + str(len(Y_list_cropped[index_test_cropped])))\n",
        "print(\"Numb of Y_hat_list:                \" + str(len(Y_hat_list[index_test_cropped])))\n",
        "print(\"Numb of T_list:                    \" + str(len(T_list[index_test])))\n",
        "print(\"Numb of T_list_np:                 \" + str(np.sum(Y_list[index_test])))\n",
        "print(\"Numb of T_hat_list:                \" + str(len(T_hat_list[index_test_cropped])))\n",
        "print(\"Numb of T_hat_list_np:             \" + str(np.sum(Y_hat_list[index_test_cropped])))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"T_list:                            \" + str(T_list[index_test]))\n",
        "print(\"T_hat_list:                        \" + str(T_hat_list[index_test_cropped]))\n",
        "\n",
        "print(\"\\n\")\n",
        "Y_int = []\n",
        "for Y_to_int in Y_list[index_test]:\n",
        "  Y_int.append(int(Y_to_int))\n",
        "print(\"Y_list:                            \" + str(Y_int))\n",
        "print(\"Y_hat_list:                        \" + str(Y_hat_list[index_test_cropped]))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"sims_list:                         \" + str(sims_list[index_test_cropped]))\n",
        "miu = np.mean(sims_list[index_test_cropped])\n",
        "sigma = np.std(sims_list[index_test_cropped])\n",
        "treshold = miu - (Z * sigma)\n",
        "sims_t_hat = []\n",
        "# for T_test in T_hat_list[index_test_cropped]:\n",
        "#   sims_t_hat.append((round(sims_list[index_test_cropped][T_test[0]],5),round(sims_list[index_test_cropped][T_test[1]],5)))\n",
        "\n",
        "sims_t = []\n",
        "# for T_test in T_list[index_test]:\n",
        "#   print(T_test)\n",
        "#   sims_t.append((round(sims_list[index_test_cropped][T_test[0]],5),round(sims_list[index_test_cropped][T_test[1]],5)))\n",
        "\n",
        "print(\"Miu:                               \" + str(round(miu,5)))\n",
        "print(\"sigma:                             \" + str(round(sigma,5)))\n",
        "print(\"treshold:                          \" + str(round(treshold,5)))\n",
        "print(\"sims_t:                            \" + str(sims_t))\n",
        "print(\"sims_t_hat:                        \" + str(sims_t_hat))\n",
        "print(\"topic_quantity_difference:         \" + str(topic_quantity_difference))\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"PK:                                \" + str(round(pk_metric,4)))\n",
        "print(\"Wd:                                \" + str(round(wd_metric,4)))\n",
        "print(\"Mean Topic Q:                      \" + str(round(np.mean(topic_quantity_difference),4)))\n",
        "print(\"Std Topic Q:                       \" + str(round(np.std(topic_quantity_difference),4)))\n",
        "print(\"MAE:                               \" + str(round(np.mean(mae),4)))\n",
        "# except Exception as error:\n",
        "#   print(datetime.today().strftime('%Y-%m-%d %H:%M:%S') + \n",
        "#         \" - \" + str(done_embedding) + \n",
        "#         \" - Error Printing results Wd\" +\n",
        "#         \"\\n\" +\n",
        "#         \" - Error: \" + str(error))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}